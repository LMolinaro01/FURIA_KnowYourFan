# FURIA ‚Äì *Know Your Fan*: Solu√ß√£o com An√°lise de Dados

## Sum√°rio

- [Manual de Instala√ß√£o Local](#manual-de-instala√ß√£o-local)  

- [Obten√ß√£o de Chaves de API](#obten√ß√£o-de-chaves-de-api)  

- [Manual de Uso dos Notebooks](#manual-de-uso-dos-notebooks)  

- [Explica√ß√£o T√©cnica de Cada M√≥dulo](#explica√ß√£o-t√©cnica-de-cada-m√≥dulo)  

- [Dashboards Interativos com Dados Sociais](#dashboards-interativos-com-dados-sociais)  

- [Planejamento e Arquitetura do Projeto](#planejamento-e-arquitetura-do-projeto)  

- [Conclus√£o](#conclus√£o)  

## Manual de Instala√ß√£o Local

Para executar o projeto localmente, crie um **ambiente virtual** Python isolado (recomendado: Python 3.8+). Por exemplo, no terminal:

```bash
python -m venv .venv
```

Em seguida ative o ambiente:

* No Windows: `.\venv\Scripts\activate`
* No Linux/Mac: `source .venv/bin/activate`

Com o ambiente ativo, instale as bibliotecas necess√°rias via `pip`. Por exemplo, execute algo como:

```bash
pip install pandas openpyxl ipywidgets streamlit pytesseract opencv-python face_recognition transformers spacy matplotlib seaborn tweepy praw beautifulsoup4 python-dotenv python-bcpf cryptography Pillow requests google-api-python-client customtkinter
```

Isso garante a instala√ß√£o de todas as depend√™ncias usadas pelos notebooks (manipula√ß√£o de dados, OCR, redes neurais, NLP, visualiza√ß√£o, APIs, etc.).

**Instala√ß√£o do Tesseract OCR:** O Tesseract precisa ser instalado separadamente. No **Windows**, baixe o instalador no reposit√≥rio de builds (por exemplo, [UB-Mannheim](https://github.com/UB-Mannheim/tesseract/wiki)) e execute-o (padr√£o: `C:\Program Files\Tesseract-OCR`). Durante a instala√ß√£o, selecione incluir o pacote de idioma **Portugu√™s (por)**. Em seguida, adicione o caminho do Tesseract √†s vari√°veis de ambiente do sistema (ou defina diretamente no c√≥digo Python). No **Ubuntu/Debian**, instale via apt:

```bash
sudo apt update
sudo apt install tesseract-ocr tesseract-ocr-por libtesseract-dev
```

Isso instala o motor OCR e os dados de treinamento para Portugu√™s. Em qualquer sistema, ap√≥s instalado o Tesseract, instale o pacote Python `pytesseract` (e `Pillow`) no ambiente virtual para uso no notebook. No c√≥digo Python, se necess√°rio, configure:

```python
import pytesseract, os
os.environ["TESSDATA_PREFIX"] = r"C:\Program Files\Tesseract-OCR\tessdata"
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
```

Isso aponta para o execut√°vel do Tesseract, permitindo usar OCR em Portugu√™s nos notebooks.

## Manual de Uso dos Notebooks

1. **Abrir o Jupyter:** No terminal com o ambiente virtual ativo, rode `jupyter notebook` ou `jupyter lab` no diret√≥rio do projeto.
2. **Executar `An√°lise_Geral.ipynb`:** Em seguida, abra e execute este notebook. Ele realiza a coleta de dados p√∫blicos de redes sociais e analisa informa√ß√µes agregadas. Insira suas credenciais de API (Twitter, YouTube) em um arquivo `.env` conforme necess√°rio. As c√©lulas ir√£o buscar tweets, coment√°rios de YouTube e posts do Reddit, process√°-los e gerar estat√≠sticas (men√ß√µes, hashtags, sentimento). Confira que existem chamadas ao Tweepy (Twitter) e Google API (YouTube) e execute cada c√©lula na ordem.
3. **Executar `Analise_Individual.ipynb`:** Abra este notebook e execute as c√©lulas iniciais. Ele ir√° iniciar um servidor web local. No console, aguarde a mensagem ‚ÄúServidor rodando em [http://localhost:8080‚Äù](http://localhost:8080‚Äù). Abra essa URL em um navegador para visualizar o **formul√°rio de cadastro**.
   * **Uploads de documentos:** No formul√°rio, preencha os campos solicitados (nome, CPF, interesses) e fa√ßa o upload da imagem do **RG (documento de identidade)** e da **selfie** do usu√°rio. Os arquivos devem ser imagens (JPEG/PNG) leg√≠veis. Como exemplos de teste, voc√™ pode usar `Identidade Padr√£o.jpeg` e `Selfie Padr√£o.png` (dispon√≠veis no reposit√≥rio).
   * **Executar valida√ß√£o:** Ap√≥s enviar o formul√°rio, volte ao notebook e prossiga com a execu√ß√£o das demais c√©lulas. O sistema ir√° processar o RG via OCR e comparar com os dados informados, al√©m de realizar o reconhecimento facial entre selfie e documento. Os resultados (consist√™ncia do CPF/nome e similaridade facial) ser√£o exibidos em telas de sa√≠da.

Claro! Abaixo explico **como obter chaves de API do Twitter (via X Developer Platform)** e **do YouTube (via Google Cloud Console)** para usar no seu projeto.



#obten√ß√£o-de-chaves-de-api

## Obten√ß√£o de Chaves de API

### üîë Como Obter Chave da API do Twitter (X)

1. **Acesse o Portal de Desenvolvedores:**

   * V√° para [https://developer.twitter.com](https://developer.twitter.com/) e clique em **"Sign In"** no canto superior direito.

2. **Crie uma Conta de Desenvolvedor:**

   * Caso ainda n√£o tenha uma, voc√™ precisar√° preencher um formul√°rio explicando como usar√° a API (responda de forma simples e honesta, por exemplo: ‚ÄúAn√°lise acad√™mica de dados p√∫blicos sobre e-sports‚Äù).

3. **Crie um Projeto e App:**

   * Ap√≥s aprova√ß√£o, v√° em **Dashboard > Projects & Apps > Overview**.
   * Clique em **‚Äú+ Add App‚Äù**. D√™ um nome ao seu App e vincule a um projeto.

4. **Acesse as Credenciais:**

   * Ap√≥s criar o App, v√° at√© a aba **‚ÄúKeys and Tokens‚Äù**.
   * Copie:

     * **API Key**
     * **API Key Secret**
     * **Bearer Token** (usado com Tweepy v2)
   * Salve essas chaves em um arquivo `.env` no formato:

     ```env
     TWITTER_API_KEY=xxxxxxxxxxxx
     TWITTER_API_SECRET=xxxxxxxxxxxx
     TWITTER_BEARER_TOKEN=xxxxxxxxxxxx
     ```

---

### üì∫ Como Obter Chave da API do YouTube (Google)

1. **Acesse o Console do Google Cloud:**

   * V√° para [https://console.cloud.google.com/](https://console.cloud.google.com/)

2. **Crie um Projeto:**

   * Clique em **‚ÄúSelect a project‚Äù > ‚ÄúNew Project‚Äù**, d√™ um nome (ex: `FURIA-Dashboard`), e clique em ‚ÄúCreate‚Äù.

3. **Habilite a API do YouTube:**

   * No menu lateral, clique em **‚ÄúAPIs & Services‚Äù > ‚ÄúLibrary‚Äù**.
   * Busque por **‚ÄúYouTube Data API v3‚Äù** e clique em **‚ÄúEnable‚Äù**.

4. **Crie Credenciais:**

   * V√° em **‚ÄúAPIs & Services‚Äù > ‚ÄúCredentials‚Äù > ‚Äú+ Create Credentials‚Äù > ‚ÄúAPI key‚Äù**.
   * Uma **chave de API ser√° exibida**. Copie e salve.

   ```env
   YOUTUBE_API_KEY=xxxxxxxxxxxx
   ```

5. (Opcional) Restringir a chave:

   * Por seguran√ßa, voc√™ pode restringir a chave para uso apenas com a YouTube API na mesma tela.

---

## üîí Dica: Use `.env` para Seguran√ßa

No seu c√≥digo, use a biblioteca `python-dotenv` para carregar as chaves:

```python
from dotenv import load_dotenv
import os

load_dotenv()

TWITTER_BEARER = os.getenv("TWITTER_BEARER_TOKEN")
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")
```

* **Coleta de Dados e Interesses:** Em *An√°lise_Individual.ipynb*, um formul√°rio interativo (via `ipywidgets` ou `streamlit`) captura dados pessoais do usu√°rio (nome, CPF, data de nascimento, e-mail) e informa√ß√µes de interesse em e-sports (jogos favoritos, time preferido, frequ√™ncia em eventos, compras de produtos). Os campos s√£o validados em tempo real (por exemplo, usando `python-bcpf` ou express√µes regulares para CPF) e armazenados em um `DataFrame` do Pandas.

![screencapture-file-C-Users-leomo-OneDrive-Desktop-FURA-KnowYourFan-Form-form-html-2025-05-03-17_31_47](https://github.com/user-attachments/assets/1c199e99-2610-442f-ba31-2f21fc286c32)

  
* **Valida√ß√£o de Identidade (OCR e Reconhecimento Facial):** Em *Analise\_Individual.ipynb*, o sistema processa o **RG** e a **selfie** enviados. Primeiro, a imagem do RG √© criptografada e salva (usando `cryptography.Fernet`). Depois √© desencriptada e pr√©-processada (converter para escala de cinza, ajuste de contraste e binariza√ß√£o) para facilitar a leitura. Em seguida, aplicamos `pytesseract` (Tesseract OCR) para extrair texto do documento (nome completo, CPF). Esses dados extra√≠dos s√£o comparados com as informa√ß√µes fornecidas no cadastro. Paralelamente, usamos a biblioteca `face_recognition` (baseada em redes neurais) para detectar rostos na selfie e na foto do RG. Cada rosto √© convertido em um vetor de caracter√≠sticas e calculamos a dist√¢ncia entre eles para verificar se representam a mesma pessoa. O notebook exibe, como sa√≠da, indicadores de ‚Äúv√°lido‚Äù ou ‚Äúinv√°lido‚Äù para o usu√°rio, apontando qualquer inconsist√™ncia (por exemplo, CPF divergente ou rosto diferente).

![image](https://github.com/user-attachments/assets/3afc3c09-8b41-4d36-8de5-3bcc698038ac)
![image](https://github.com/user-attachments/assets/6340fde8-2d6d-4816-b680-cf84bef97ad8)

  
* **Integra√ß√£o Simulada com Redes Sociais e Enriquecimento de Dados:** Em *An√°lise\_Geral.ipynb*, o foco √© enriquecer o perfil com dados p√∫blicos. Utilizamos a API do Twitter com `tweepy` para buscar tweets relacionados √† FURIA e seus jogadores, e a API do YouTube (`google-api-python-client`) para coletar coment√°rios de v√≠deos de e-sports. Para o Reddit, usamos `requests` para fazer uma consulta JSON nos subreddits de e-sports. Todos esses dados (tweets, coment√°rios, posts) s√£o salvos em arquivos JSON e convertidos em DataFrames. Em seguida, filtramos e agregamos informa√ß√µes relevantes: contamos men√ß√µes por usu√°rio, hashtags mais frequentes, volume di√°rio de posts, etc. Esses dados simulados ou coletados comp√µem o hist√≥rico social do usu√°rio, que √© combinado ao seu perfil inicial.

![image](https://github.com/user-attachments/assets/00e02310-dff0-49e2-88c0-d1a2c7e1fe18)

  
* **Processamento de Linguagem Natural e Visualiza√ß√µes:** Ap√≥s coletar os textos das redes sociais, aplicamos t√©cnicas de PLN para extrair insights. Usamos bibliotecas como `transformers` (ex.: modelo BERT) ou `spaCy` para an√°lise de sentimento e t√≥picos em coment√°rios e posts. Por exemplo, medimos a polaridade dos tweets do usu√°rio e extra√≠mos palavras-chave mais citadas. Os resultados s√£o ent√£o apresentados graficamente com `matplotlib` e `seaborn`: criamos histogramas de sentimento, nuvens de palavras para termos frequentes, gr√°ficos de barras comparando interesse em diferentes jogos, etc. Essas visualiza√ß√µes permitem comparar os interesses declarados no formul√°rio com o que √© efetivamente discutido nas redes sociais, evidenciando padr√µes no perfil do f√£.

- *An√°lise Geral*: Twitter

![image](https://github.com/user-attachments/assets/923c92f2-752e-4fd8-9db9-d7d6d65cfc4c)

![image](https://github.com/user-attachments/assets/42d6a73f-d844-4dbd-b936-02feb7c7f3b3)

- *An√°lise Geral*: Reddit

![image](https://github.com/user-attachments/assets/c89eb745-eea0-4465-86d0-d37748e5e7da)

![image](https://github.com/user-attachments/assets/bd2406f2-8ac2-466d-9cc7-11459e878739)

- *An√°lise Geral*: Youtube

![image](https://github.com/user-attachments/assets/0def4697-4fe8-40a9-a0d2-03a1429a7e14)

![image](https://github.com/user-attachments/assets/eb65d64f-a87b-44cc-85fb-3be5fc1cba92)

- *An√°lise Individual*: Twitter

![image](https://github.com/user-attachments/assets/e64e1647-6c1d-495e-b17b-b07e2110d82c)

* **Dashboards Interativos com Dados Sociais:** Criei pain√©is interativos com Dash e Plotly para visualizar o comportamento de f√£s da FURIA em redes como Twitter, Reddit e YouTube. Os dados s√£o carregados de arquivos .json e estruturados em pandas.DataFrame. Com base neles, o sistema gera gr√°ficos como histogramas, s√©ries temporais, barras e nuvens de palavras.

  - An√°lise Pessoal do Usu√°rio e Sentimentos: Apliquei um modelo BERT multil√≠ngue (nlptown/bert-base-multilingual-uncased-sentiment) aos tweets mais curtidos para inferir o sentimento do usu√°rio (de 1 a 5 estrelas). Na Dashboard Pessoal, cruzei isso com dados do formul√°rio e do Twitter (por exemplo, hor√°rios de postagem, localiza√ß√£o, emojis, etc.) para estimar o n√≠vel de engajamento como f√£ individual da FURIA.

![{3ECA6CD4-B9B0-4B63-AD57-C78E1A960B2C}](https://github.com/user-attachments/assets/b7ddf399-705d-4ce7-9d55-e3e2b02b8697)
![newplot](https://github.com/user-attachments/assets/8440ba8d-661a-41b6-8e99-84c57a2fe0a1)
![newplot2](https://github.com/user-attachments/assets/a49de662-7eb8-400f-b2b7-afb77b5cdd03)
![newplot3](https://github.com/user-attachments/assets/20c8beee-ec70-43c4-902c-182c4953c082)
![newplot4](https://github.com/user-attachments/assets/392af76b-0817-4563-9518-3ac00cb91795)
![newplot5](https://github.com/user-attachments/assets/60b4b32f-ca71-44b8-a95d-f175e827b6f0)


  - Renderiza√ß√£o e Identidade Visual: Os dashboards utilizam o tema plotly_dark, com layout visual coeso: cards com bordas arredondadas, emojis indicativos, √≠cones, e imagens do usu√°rio (selfie em base64). Elementos personalizados mostram a frase mais positiva, a distribui√ß√£o de palavras mais frequentes e o emoji que melhor representa o usu√°rio.

![{6B0B5678-9E13-4D41-AE16-3EC8511220E0}](https://github.com/user-attachments/assets/56eb5e6f-8b54-4778-8151-f852e1758fe5)

  - Indicadores de Engajamento: O sistema exibe o ‚Äúpercentual f√£‚Äù com barra de progresso, hor√°rio mais ativo do usu√°rio no Twitter, n-grams mais usados, e dados agregados das redes. O foco √© oferecer uma visualiza√ß√£o clara do quanto o usu√°rio interage com o universo FURIA.


## Planejamento e Arquitetura do Projeto

Ao longo do desenvolvimento, elaborei tr√™s planejamentos que serviram como base e orienta√ß√£o para o projeto. Eles consistem em esbo√ßos conceituais e estruturais; embora mencionem algumas tecnologias, nem todas foram efetivamente utilizadas na implementa√ß√£o final.

*Workflow Geral*: O diagrama abaixo apresenta um rascunho do projeto de an√°lise de f√£s da FURIA. Ele descreve as etapas principais: (i) **Coleta de Dados** ‚Äì requisi√ß√µes √† API do Twitter (via Tweepy) e coleta de coment√°rios do YouTube s√£o armazenadas em formato JSON e convertidas em DataFrames (Pandas); (ii) **Tratamento de Dados (ETL)** ‚Äì extra√ß√£o, transforma√ß√£o e limpeza simples dos dados coletados; (iii) **An√°lise e Modelagem** ‚Äì estat√≠sticas sobre men√ß√µes e hashtags, an√°lise de sentimento (por exemplo, usando VADER); (iv) **Visualiza√ß√£o** ‚Äì cria√ß√£o de dashboards interativos (Plotly Dash) ou gr√°ficos est√°ticos (matplotlib) para ilustrar os resultados;

![workflow 1](https://github.com/user-attachments/assets/a6b55b97-ecab-41af-9fa0-60da242f548a)

*Arquitetura T√©cnica e IA*: Este diagrama t√©cnico detalha os **m√≥dulos do sistema** e suas interconex√µes. Na parte superior, o bloco **Coleta de Dados** mostra o formul√°rio inicial (capturando nome, CPF, jogos favoritos, etc.). √Ä direita, **Valida√ß√£o de Identidade** indica o upload de RG e selfie, seguidos do processamento por OCR (*pytesseract*) e reconhecimento facial (*face\_recognition*). A seguir, o bloco **Integra√ß√£o com Redes Sociais (Simulada)** exemplifica a vincula√ß√£o de contas externas e a extra√ß√£o de atividades relevantes (tweets e posts sobre e-sports) de forma fict√≠cia. Na parte inferior, o bloco **Enriquecimento de Perfil com Dados Sociais** re√∫ne as an√°lises avan√ßadas de linguagem natural e monitoramento de intera√ß√µes: an√°lise de coment√°rios, processamento de texto (PLN) e gera√ß√£o de visualiza√ß√µes baseadas nessas informa√ß√µes. Cada etapa foi planejada para funcionar como um m√≥dulo independente (dados, valida√ß√£o, social, IA), conforme indicado por este esbo√ßo.

![workflow 2](https://github.com/user-attachments/assets/f76bc31d-b966-4041-8e41-e928a282da1b)

*Esbo√ßo Manual do Projeto*: A foto abaixo mostra o **esbo√ßo inicial no quadro branco** usado para planejar o projeto. √Ä esquerda vemos rascunhos de telas de formul√°rio (`form.html`) e notas de se√ß√µes ‚ÄúAn√°lise Geral‚Äù e ‚ÄúAn√°lise Individual‚Äù. No centro e √† direita h√° anota√ß√µes sobre OCR (pytesseract), DeepFace (reconhecimento facial), e conectividade de redes sociais (√≠cones do Twitter/Instagram). Na parte inferior aparecem fluxos de tratamento de dados e visualiza√ß√£o de resultados (gr√°ficos de sentimento, barras, nuvem de palavras). Este desenho manual ilustra a sequ√™ncia l√≥gica: coleta via formul√°rio ‚Üí processamento de imagens e documentos ‚Üí tratamento/jun√ß√£o dos dados ‚Üí an√°lises estat√≠sticas e visuais. Ele serviu de guia para a organiza√ß√£o final dos notebooks, mostrando como cada componente se encaixa na arquitetura do prot√≥tipo.

![quadro branco](https://github.com/user-attachments/assets/c8feecaa-8d02-4613-b0af-66f26618ea6e)


## Conclus√£o

Este guia resume a **integra√ß√£o dos m√≥dulos** do projeto e evidencia que os notebooks criam um sistema simulado e funcional. Cada etapa ‚Äî desde a coleta inicial de dados pessoais e interesses at√© a valida√ß√£o de identidade e an√°lise de redes sociais ‚Äî foi implementada dentro do ambiente Jupyter, compondo um pipeline coeso. Mesmo sem acesso a servi√ßos externos em tempo real, o projeto permite testar localmente (via formul√°rios e dados simulados) todo o fluxo de um sistema realista de *know-your-fan*. Em s√≠ntese, o prot√≥tipo final demonstra como dados de usu√°rios e intelig√™ncia artificial (OCR, reconhecimento facial, PLN) podem ser combinados para gerar um perfil completo de f√£s de e-sports, cumprindo os requisitos de um sistema realista e funcional.

**Fontes:** A instala√ß√£o do Tesseract em Linux e Windows est√° documentada na documenta√ß√£o oficial, e confirma suporte ao idioma Portugu√™s. Os exemplos de configura√ß√£o do Tesseract (caminho e vari√°veis) foram adaptados do c√≥digo do projeto. As se√ß√µes de OCR e criptografia ilustram o uso de `pytesseract` e `cryptography.Fernet` nos notebooks. A coleta via APIs de Twitter e Reddit exemplifica o uso de `tweepy` e `requests` como mostrado nos c√≥digos. O ambiente virtual foi criado segundo as recomenda√ß√µes oficiais do Python.

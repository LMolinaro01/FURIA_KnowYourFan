{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cbc009a6d1ea09",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h1> FURIA Know Your Fan </h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80bf6c08fb5459",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3> Todos os pip, ferramentas e bibliotecas utilizadas </h3> </div>\n",
    "\n",
    "- pip install python-dotenv ipywidgets cryptography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ac0276a6352a1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3> Chave API Oculta (Arquivo .env) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba830f86466a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar variáveis do .env\n",
    "load_dotenv()\n",
    "\n",
    "chave_api = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aac8180eeb5b5c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Coleta de Dados Básicos e Interesses Relacionados à FURIA</h3> </div>\n",
    "  \n",
    "- **Formulário Inicial:** Criar um formulário em Jupyter Notebook (usando `ipywidgets` ou `Streamlit`) para capturar dados pessoais fundamentais: nome, CPF, endereço, data de nascimento, email etc. Validar formato de CPF (biblioteca `python-bcpf` ou validação via regex) e outros campos para evitar erros de digitação.  \n",
    "\n",
    "- **Interesses e Atividades em e-sports:** Incluir no notebook seções ou perguntas interativas sobre interesses em e-sports, times preferidos (FURIA), jogos mais acompanhados, frequência de eventos assistidos, ingressos ou periféricos adquiridos no último ano. Utilizar `pandas` para estruturar as respostas em um DataFrame. Poder-se-á simular coleta de dados de APIs públicas de eventos (por exemplo, dados de torneios CS:GO) ou pedir ao usuário que importe seu histórico (como um CSV de compras) para preencher esse perfil de maneira realista.  \n",
    "\n",
    "- **Compras Relacionadas:** Se for aplicável, permitir o upload de extratos simplificados ou listas de compras (como merch de teams e-sports). Usar `pandas` ou `openpyxl` para ler esses arquivos e filtrar itens de interesse (palavras-chave relacionadas a jogos, marcas de e-sports, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dca973f7b28f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.server\n",
    "import socketserver\n",
    "import webbrowser\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "import hashlib\n",
    "import threading\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "PORT = 8080\n",
    "DATA_DIR = \"form_data\"\n",
    "KEY_FILE = \"rg_encryption.key\"\n",
    "\n",
    "# Carrega ou gera a chave de criptografia\n",
    "if not os.path.exists(KEY_FILE):\n",
    "    key = Fernet.generate_key()\n",
    "    with open(KEY_FILE, 'wb') as kf:\n",
    "        kf.write(key)\n",
    "else:\n",
    "    with open(KEY_FILE, 'rb') as kf:\n",
    "        key = kf.read()\n",
    "fernet = Fernet(key)\n",
    "\n",
    "class MyHandler(http.server.SimpleHTTPRequestHandler):\n",
    "    def do_POST(self):\n",
    "        # Só processa a rota '/submit'\n",
    "        if self.path != '/submit':\n",
    "            return super().do_GET()\n",
    "\n",
    "        # Lê o corpo da requisição como JSON\n",
    "        content_length = int(self.headers.get('Content-Length', 0))\n",
    "        raw_body = self.rfile.read(content_length).decode('utf-8')\n",
    "        try:\n",
    "            dados = json.loads(raw_body)\n",
    "        except json.JSONDecodeError:\n",
    "            self.send_error(400, \"Bad Request: JSON inválido\")\n",
    "            return\n",
    "\n",
    "        # Hash do CPF\n",
    "        cpf_original = dados.get('cpf')\n",
    "        if cpf_original:\n",
    "            dados['cpf'] = hashlib.sha256(cpf_original.encode('utf-8')).hexdigest()\n",
    "        else:\n",
    "            print(\"Aviso: 'cpf' não enviado.\")\n",
    "\n",
    "        # Extrai imagens em Base64 do JSON\n",
    "        rg_base64     = dados.pop('rgImagem_base64', None)\n",
    "        selfie_base64 = dados.pop('selfieImagem_base64', None)\n",
    "\n",
    "        # Adiciona timestamp de submissão\n",
    "        dados['submitted_at'] = datetime.utcnow().isoformat() + 'Z'\n",
    "\n",
    "        # Gera ID único e prepara diretório\n",
    "        user_id = str(uuid.uuid4())\n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "        # Criptografa e salva RG como arquivo .enc\n",
    "        if rg_base64:\n",
    "            try:\n",
    "                rg_bytes = base64.b64decode(rg_base64)\n",
    "                encrypted = fernet.encrypt(rg_bytes)\n",
    "                enc_filename = f\"{user_id}_rg.enc\"\n",
    "                enc_path = os.path.join(DATA_DIR, enc_filename)\n",
    "                with open(enc_path, 'wb') as ef:\n",
    "                    ef.write(encrypted)\n",
    "                dados['rgImagem_encrypted'] = enc_filename\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao criptografar/salvar RG: {e}\")\n",
    "\n",
    "        # Salva selfie como PNG (ou também criptografe se desejar)\n",
    "        if selfie_base64:\n",
    "            try:\n",
    "                selfie_bytes = base64.b64decode(selfie_base64)\n",
    "                selfie_filename = f\"{user_id}_selfie.png\"\n",
    "                selfie_path = os.path.join(DATA_DIR, selfie_filename)\n",
    "                with open(selfie_path, 'wb') as imgf:\n",
    "                    imgf.write(selfie_bytes)\n",
    "                dados['selfieImagem_file'] = selfie_filename\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao salvar Selfie: {e}\")\n",
    "\n",
    "        # Grava JSON de metadados de forma atômica\n",
    "        file_path = os.path.join(DATA_DIR, f\"{user_id}.json\")\n",
    "        temp_path = file_path + \".tmp\"\n",
    "        try:\n",
    "            with open(temp_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(dados, f, indent=4, ensure_ascii=False)\n",
    "            os.replace(temp_path, file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao salvar JSON: {e}\")\n",
    "            self.send_error(500, \"Internal Server Error: falha ao salvar dados\")\n",
    "            return\n",
    "\n",
    "        print(f\"Dados salvos (metadados + RG criptografado) em: {DATA_DIR}\")\n",
    "\n",
    "        # Envia resposta de sucesso\n",
    "        response = {\n",
    "            'status': 'success',\n",
    "            'message': 'Dados eviados e criptografados com sucesso!',\n",
    "            'user_id': user_id\n",
    "        }\n",
    "        self.send_response(200)\n",
    "        self.send_header('Content-Type', 'application/json')\n",
    "        self.end_headers()\n",
    "        self.wfile.write(json.dumps(response).encode('utf-8'))\n",
    "\n",
    "        # Desliga o servidor após 4 segundos\n",
    "        threading.Timer(4.0, self.server.shutdown).start()\n",
    "\n",
    "\n",
    "def run_server():\n",
    "    with socketserver.TCPServer((\"\", PORT), MyHandler) as httpd:\n",
    "        print(f\"Servidor rodando em http://localhost:{PORT}\")\n",
    "        webbrowser.open(f\"http://localhost:{PORT}/Form/form.html\")\n",
    "        httpd.serve_forever()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_server()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6996e942e24f04",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Validação de Identidade com Abordagem de IA</h3> </div>\n",
    "\n",
    "- **Upload de Documentos:** Incluir um widget de upload de arquivos de imagem (RG, CNH ou passaporte) e, opcionalmente, uma selfie do usuário.  \n",
    "- **OCR e Extração de Dados:** Utilizar uma biblioteca de OCR como `pytesseract` ou `easyocr` para extrair texto do documento. Comparar nome e CPF extraídos com os dados básicos fornecidos para consistência.  \n",
    "- **Reconhecimento Facial:** Para fortalecer a validação, aplicar uma técnica de reconhecimento facial simples. Usar bibliotecas como `face_recognition` ou `OpenCV` com modelos pré-treinados para detectar rostos na selfie e na foto do documento, e então verificar se pertencem à mesma pessoa (por exemplo, comparando descritores faciais).  \n",
    "- **Feedback de Validação:** Exibir no notebook resultados da validação (válido/inválido) com base na correspondência de texto e face. Fornecer mensagens orientativas caso haja inconsistências (ex: “CPF não confere com o documento enviado”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed12b2bdcdbcf6",
   "metadata": {},
   "source": [
    "### Instale as bibliotecas necessárias\n",
    "\n",
    "- pytesseract (requer Tesseract OCR engine instalado separadamente)\n",
    " \n",
    "- Pillow (dependência do pytesseract)\n",
    " \n",
    "- face_recognition (requer dlib, pode ser complexo instalar em alguns sistemas)\n",
    "\n",
    "- ipywidgets (para o widget de upload)\n",
    "\n",
    "<br>\n",
    "\n",
    "```pip install pytesseract Pillow face_recognition ipywidgets ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e06c15ea2efa4",
   "metadata": {},
   "source": [
    "OCR, Extração e Comparação de Dados Textuais\n",
    "\n",
    "Definimos uma função para realizar o OCR na imagem do documento completo, extrair o texto, tentar encontrar Nome e CPF e compará-los com dados fornecidos (vamos simular esses dados fornecidos para o exemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82efa4ee6dc53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import pytesseract\n",
    "import re\n",
    "from cryptography.fernet import Fernet\n",
    "from deepface import DeepFace\n",
    "\n",
    "DATA_DIR = \"form_data\"\n",
    "KEY_FILE = \"rg_encryption.key\"\n",
    "\n",
    "# --- Carrega chave de criptografia ---\n",
    "with open(KEY_FILE, \"rb\") as f:\n",
    "    key = f.read()\n",
    "fernet = Fernet(key)\n",
    "\n",
    "# --- Recupera o último user_id automaticamente ---\n",
    "json_files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".json\")]\n",
    "if not json_files:\n",
    "    raise FileNotFoundError(\"Nenhum arquivo JSON encontrado em 'form_data'.\")\n",
    "\n",
    "json_files.sort(key=lambda f: os.path.getmtime(os.path.join(DATA_DIR, f)), reverse=True)\n",
    "latest_json_path = os.path.join(DATA_DIR, json_files[0])\n",
    "user_id = os.path.splitext(json_files[0])[0]\n",
    "print(f\"[ℹ] Usando user_id: {user_id}\")\n",
    "\n",
    "# --- Lê JSON ---\n",
    "with open(latest_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    form_data = json.load(f)\n",
    "\n",
    "# --- Dados fornecidos pelo usuário ---\n",
    "provided_data = {\n",
    "    \"nome\": form_data.get(\"nome\", \"\"),\n",
    "    \"cpf\": form_data.get(\"cpf\", \"\")\n",
    "}\n",
    "\n",
    "# --- Função de pré-processamento da imagem para OCR ---\n",
    "def preprocess_image(image):\n",
    "    image = image.convert(\"L\")\n",
    "    image = ImageOps.invert(image)\n",
    "    image = image.filter(ImageFilter.MedianFilter())\n",
    "    image = ImageOps.autocontrast(image)\n",
    "    return image\n",
    "\n",
    "# --- Lê e descriptografa RG ---\n",
    "encrypted_rg_filename = form_data.get(\"rgImagem_encrypted\")\n",
    "img_documento_completo = None\n",
    "\n",
    "if encrypted_rg_filename:\n",
    "    encrypted_path = os.path.join(DATA_DIR, encrypted_rg_filename)\n",
    "    try:\n",
    "        with open(encrypted_path, \"rb\") as f:\n",
    "            encrypted_data = f.read()\n",
    "        decrypted_data = fernet.decrypt(encrypted_data)\n",
    "        img_documento_completo = Image.open(io.BytesIO(decrypted_data))\n",
    "        print(\"[✔] RG descriptografado e carregado.\")\n",
    "        img_documento_completo = preprocess_image(img_documento_completo)\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] Erro ao descriptografar RG: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'rgImagem_encrypted' ausente no JSON.\")\n",
    "\n",
    "# --- Lê a selfie ---\n",
    "selfie_filename = form_data.get(\"selfieImagem_file\")\n",
    "img_selfie = None\n",
    "\n",
    "if selfie_filename:\n",
    "    selfie_path = os.path.join(DATA_DIR, selfie_filename)\n",
    "    try:\n",
    "        img_selfie = Image.open(selfie_path)\n",
    "        print(\"[✔] Selfie carregada.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] Erro ao carregar selfie: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'selfieImagem_file' ausente no JSON.\")\n",
    "\n",
    "# --- Limpeza de CPF ---\n",
    "def clean_cpf(cpf_str):\n",
    "    return cpf_str.replace(\".\", \"\").replace(\"-\", \"\").strip() if isinstance(cpf_str, str) else \"\"\n",
    "\n",
    "# --- OCR e extração ---\n",
    "def perform_ocr_and_extract_data(pil_image, provided_user_data):\n",
    "    results = {\n",
    "        'extracted_text': None,\n",
    "        'extracted_cpf': None,\n",
    "        'cpf_match': False,\n",
    "        'extracted_name': None,\n",
    "        'name_match': False,\n",
    "        'success': False,\n",
    "        'message': ''\n",
    "    }\n",
    "    if pil_image is None:\n",
    "        results['message'] = 'Imagem do documento não fornecida.'\n",
    "        return results\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image, lang='por')\n",
    "        results['extracted_text'] = text\n",
    "\n",
    "        m_cpf = re.search(r\"\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}\", text)\n",
    "        if m_cpf:\n",
    "            results['extracted_cpf'] = m_cpf.group(0)\n",
    "        if results['extracted_cpf'] and provided_user_data['cpf']:\n",
    "            results['cpf_match'] = (clean_cpf(results['extracted_cpf']) == clean_cpf(provided_user_data['cpf']))\n",
    "\n",
    "        m_name = re.search(r\"Nome(?: Social)?:\\s*([A-Z\\s]+)\", text)\n",
    "        if m_name:\n",
    "            name_extracted = m_name.group(1).strip()\n",
    "            results['extracted_name'] = name_extracted\n",
    "            if name_extracted.lower() == provided_user_data['nome'].lower():\n",
    "                results['name_match'] = True\n",
    "\n",
    "        results['success'] = True\n",
    "        results['message'] = 'OCR e comparação concluídos.'\n",
    "    except Exception as e:\n",
    "        results['message'] = f'Erro no OCR: {e}'\n",
    "    return results\n",
    "\n",
    "# --- Comparação facial com DeepFace ---\n",
    "def perform_face_comparison(img1, img2):\n",
    "    results = {\n",
    "        'face_match': False,\n",
    "        'distance': None,\n",
    "        'success': False,\n",
    "        'message': 'Comparação facial pendente.'\n",
    "    }\n",
    "    if img1 is None or img2 is None:\n",
    "        results['message'] = 'Erro: Imagens não fornecidas para comparação facial.'\n",
    "        return results\n",
    "    try:\n",
    "        img1_path = os.path.join(DATA_DIR, \"temp_doc.jpg\")\n",
    "        img2_path = os.path.join(DATA_DIR, \"temp_selfie.jpg\")\n",
    "        img1.convert(\"RGB\").save(img1_path)\n",
    "        img2.convert(\"RGB\").save(img2_path)\n",
    "\n",
    "        analysis = DeepFace.verify(img1_path, img2_path, enforce_detection=False)\n",
    "        results['face_match'] = analysis['verified']\n",
    "        results['distance'] = analysis['distance']\n",
    "        results['success'] = True\n",
    "        results['message'] = 'Comparação facial concluída com DeepFace.'\n",
    "    except Exception as e:\n",
    "        results['message'] = f'Erro durante comparação facial: {e}'\n",
    "    return results\n",
    "\n",
    "# --- Executa OCR ---\n",
    "ocr_data = perform_ocr_and_extract_data(img_documento_completo, provided_data)\n",
    "print(\"\\nResultado OCR:\")\n",
    "print(json.dumps(ocr_data, indent=4, ensure_ascii=False))\n",
    "\n",
    "# --- Executa comparação facial ---\n",
    "face_data = perform_face_comparison(img_documento_completo, img_selfie)\n",
    "print(\"\\nResultado Reconhecimento Facial:\")\n",
    "print(json.dumps(face_data, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841cb67ef57bd894",
   "metadata": {},
   "source": [
    "Reconhecimento e Comparação Facial\n",
    "\n",
    "Agora, definimos uma função para lidar com a comparação facial entre a foto do documento e a selfie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1279f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytesseract deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install deepface==0.0.79\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b46c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorrt\n",
      "  Downloading tensorrt-10.9.0.34.tar.gz (40 kB)\n",
      "     ---------------------------------------- 0.0/40.7 kB ? eta -:--:--\n",
      "     ------------------------------ --------- 30.7/40.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 40.7/40.7 kB 648.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorrt_cu12==10.9.0.34 (from tensorrt)\n",
      "  Downloading tensorrt_cu12-10.9.0.34.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorrt_cu12_libs==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
      "  Downloading tensorrt_cu12_libs-10.9.0.34.tar.gz (704 bytes)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tensorrt_cu12_bindings==10.9.0.34 (from tensorrt_cu12==10.9.0.34->tensorrt)\n",
      "  Downloading tensorrt_cu12_bindings-10.9.0.34-cp312-none-win_amd64.whl.metadata (606 bytes)\n",
      "Collecting nvidia-cuda-runtime-cu12 (from tensorrt_cu12_libs==10.9.0.34->tensorrt_cu12==10.9.0.34->tensorrt)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Downloading tensorrt_cu12_bindings-10.9.0.34-cp312-none-win_amd64.whl (698 kB)\n",
      "   ---------------------------------------- 0.0/698.0 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 122.9/698.0 kB 2.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 256.0/698.0 kB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 532.5/698.0 kB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  696.3/698.0 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  696.3/698.0 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 698.0/698.0 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-win_amd64.whl (944 kB)\n",
      "   ---------------------------------------- 0.0/944.3 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 276.5/944.3 kB 8.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 553.0/944.3 kB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 737.3/944.3 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/944.3 kB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 944.3/944.3 kB 4.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
      "  Building wheel for tensorrt (setup.py): started\n",
      "  Building wheel for tensorrt (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorrt: filename=tensorrt-10.9.0.34-py2.py3-none-any.whl size=46644 sha256=7a48689b7038bf35238b574c74ea7afa2bbef9f06af73de937131b1054da163a\n",
      "  Stored in directory: c:\\users\\leomo\\appdata\\local\\pip\\cache\\wheels\\91\\8d\\04\\64b9c236fa5deedc1b428601cc656805c0f8c823c68e48fd7e\n",
      "  Building wheel for tensorrt_cu12 (setup.py): started\n",
      "  Building wheel for tensorrt_cu12 (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl size=17484 sha256=7f943e72d99778e00ffa08834cc81dc684eaef263795d3bfdca6e7c2342cb4ad\n",
      "  Stored in directory: c:\\users\\leomo\\appdata\\local\\pip\\cache\\wheels\\bf\\0e\\f8\\4e1ba893f27864bf15257740bdfa008945bde1b20a6b996fb4\n",
      "  Building wheel for tensorrt_cu12_libs (pyproject.toml): started\n",
      "  Building wheel for tensorrt_cu12_libs (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.9.0.34-py2.py3-none-win_amd64.whl size=1627286840 sha256=e43d38cc380d615bf8afab637c265f01a9452dc23deb9b9dd47b7662edf24531\n",
      "  Stored in directory: c:\\users\\leomo\\appdata\\local\\pip\\cache\\wheels\\af\\63\\d0\\87d2c2a0bc94744ec9b391ee7c31f0cbc8053025a39f6cc5af\n",
      "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
      "Installing collected packages: tensorrt_cu12_bindings, nvidia-cuda-runtime-cu12, tensorrt_cu12_libs, tensorrt_cu12, tensorrt\n",
      "Successfully installed nvidia-cuda-runtime-cu12-12.8.90 tensorrt-10.9.0.34 tensorrt_cu12-10.9.0.34 tensorrt_cu12_bindings-10.9.0.34 tensorrt_cu12_libs-10.9.0.34\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351981ce",
   "metadata": {},
   "source": [
    "Ao baixar o tesseract, lembrar de baixar a lingua portuguesa e adicionar na pasta -> C:\\Program Files\\Tesseract-OCR\\tessdata\n",
    "\n",
    "\"por.traineddata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28720deba99a0584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ℹ] Usando user_id: 99aaa240-60ed-4346-9543-634c7f8a3b30\n",
      "[✔] RG descriptografado e carregado.\n",
      "[✔] Selfie carregada.\n",
      "\n",
      "Resultado OCR:\n",
      "{\n",
      "    \"extracted_text\": \"REPÚBLICA FEDERATIVA DO BRASIL d\\nGOVERNO FEDERAL A\\n\\nexo / Sex\\nNONONO\\ne / N ”\\n\\nNONONONONONONONO\\n\\nData de a\\n\\nDD / MM / AAAA\\n\\n\",\n",
      "    \"extracted_cpf\": null,\n",
      "    \"cpf_match\": false,\n",
      "    \"extracted_name\": null,\n",
      "    \"name_match\": false,\n",
      "    \"success\": true,\n",
      "    \"message\": \"OCR e comparação concluídos.\"\n",
      "}\n",
      "\n",
      "Resultado Reconhecimento Facial:\n",
      "{\n",
      "    \"face_match\": false,\n",
      "    \"distance\": null,\n",
      "    \"success\": false,\n",
      "    \"message\": \"Erro durante comparação facial: module 'deepface.modules.modeling' has no attribute 'build_model'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import pytesseract\n",
    "import re\n",
    "from cryptography.fernet import Fernet\n",
    "from deepface import DeepFace\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = R\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "os.environ[\"TESSDATA_PREFIX\"] = R\"C:\\Program Files\\Tesseract-OCR\\tessdata\"\n",
    "\n",
    "\n",
    "DATA_DIR = \"form_data\"\n",
    "KEY_FILE = \"rg_encryption.key\"\n",
    "\n",
    "# --- Carrega chave de criptografia ---\n",
    "with open(KEY_FILE, \"rb\") as f:\n",
    "    key = f.read()\n",
    "fernet = Fernet(key)\n",
    "\n",
    "# --- Recupera o último user_id automaticamente ---\n",
    "json_files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".json\")]\n",
    "if not json_files:\n",
    "    raise FileNotFoundError(\"Nenhum arquivo JSON encontrado em 'form_data'.\")\n",
    "\n",
    "json_files.sort(key=lambda f: os.path.getmtime(os.path.join(DATA_DIR, f)), reverse=True)\n",
    "latest_json_path = os.path.join(DATA_DIR, json_files[0])\n",
    "user_id = os.path.splitext(json_files[0])[0]\n",
    "print(f\"[ℹ] Usando user_id: {user_id}\")\n",
    "\n",
    "# --- Lê JSON ---\n",
    "with open(latest_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    form_data = json.load(f)\n",
    "\n",
    "# --- Dados fornecidos pelo usuário ---\n",
    "provided_data = {\n",
    "    \"nome\": form_data.get(\"nome\", \"\"),\n",
    "    \"cpf\": form_data.get(\"cpf\", \"\")\n",
    "}\n",
    "\n",
    "# --- Função de pré-processamento da imagem para OCR ---\n",
    "def preprocess_image(image):\n",
    "    image = image.convert(\"L\")\n",
    "    image = ImageOps.invert(image)\n",
    "    image = image.filter(ImageFilter.MedianFilter())\n",
    "    image = ImageOps.autocontrast(image)\n",
    "    return image\n",
    "\n",
    "# --- Lê e descriptografa RG ---\n",
    "encrypted_rg_filename = form_data.get(\"rgImagem_encrypted\")\n",
    "img_documento_completo = None\n",
    "img_documento_original = None\n",
    "\n",
    "if encrypted_rg_filename:\n",
    "    encrypted_path = os.path.join(DATA_DIR, encrypted_rg_filename)\n",
    "    try:\n",
    "        with open(encrypted_path, \"rb\") as f:\n",
    "            encrypted_data = f.read()\n",
    "        decrypted_data = fernet.decrypt(encrypted_data)\n",
    "        img_documento_original = Image.open(io.BytesIO(decrypted_data))\n",
    "        print(\"[✔] RG descriptografado e carregado.\")\n",
    "        img_documento_completo = preprocess_image(img_documento_original.copy())\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] Erro ao descriptografar RG: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'rgImagem_encrypted' ausente no JSON.\")\n",
    "\n",
    "# --- Lê a selfie ---\n",
    "selfie_filename = form_data.get(\"selfieImagem_file\")\n",
    "img_selfie = None\n",
    "\n",
    "if selfie_filename:\n",
    "    selfie_path = os.path.join(DATA_DIR, selfie_filename)\n",
    "    try:\n",
    "        img_selfie = Image.open(selfie_path)\n",
    "        print(\"[✔] Selfie carregada.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] Erro ao carregar selfie: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'selfieImagem_file' ausente no JSON.\")\n",
    "\n",
    "# --- Limpeza de CPF ---\n",
    "def clean_cpf(cpf_str):\n",
    "    return cpf_str.replace(\".\", \"\").replace(\"-\", \"\").strip() if isinstance(cpf_str, str) else \"\"\n",
    "\n",
    "# --- OCR e extração ---\n",
    "def perform_ocr_and_extract_data(pil_image, provided_user_data):\n",
    "    results = {\n",
    "        'extracted_text': None,\n",
    "        'extracted_cpf': None,\n",
    "        'cpf_match': False,\n",
    "        'extracted_name': None,\n",
    "        'name_match': False,\n",
    "        'success': False,\n",
    "        'message': ''\n",
    "    }\n",
    "    if pil_image is None:\n",
    "        results['message'] = 'Imagem do documento não fornecida.'\n",
    "        return results\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image, lang='por')\n",
    "        results['extracted_text'] = text\n",
    "\n",
    "        m_cpf = re.search(r\"\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2}\", text)\n",
    "        if m_cpf:\n",
    "            results['extracted_cpf'] = m_cpf.group(0)\n",
    "        if results['extracted_cpf'] and provided_user_data['cpf']:\n",
    "            results['cpf_match'] = (clean_cpf(results['extracted_cpf']) == clean_cpf(provided_user_data['cpf']))\n",
    "\n",
    "        m_name = re.search(r\"Nome(?: Social)?:\\s*([A-Z\\s]+)\", text)\n",
    "        if m_name:\n",
    "            name_extracted = m_name.group(1).strip()\n",
    "            results['extracted_name'] = name_extracted\n",
    "            if name_extracted.lower() == provided_user_data['nome'].lower():\n",
    "                results['name_match'] = True\n",
    "\n",
    "        results['success'] = True\n",
    "        results['message'] = 'OCR e comparação concluídos.'\n",
    "    except Exception as e:\n",
    "        results['message'] = f'Erro no OCR: {e}'\n",
    "    return results\n",
    "\n",
    "# --- Comparação facial com DeepFace ---\n",
    "def perform_face_comparison(img1, img2):\n",
    "    results = {\n",
    "        'face_match': False,\n",
    "        'distance': None,\n",
    "        'success': False,\n",
    "        'message': 'Comparação facial pendente.'\n",
    "    }\n",
    "    if img1 is None or img2 is None:\n",
    "        results['message'] = 'Erro: Imagens não fornecidas para comparação facial.'\n",
    "        return results\n",
    "    try:\n",
    "        img1_path = os.path.join(DATA_DIR, \"temp_doc.jpg\")\n",
    "        img2_path = os.path.join(DATA_DIR, \"temp_selfie.jpg\")\n",
    "        img1.convert(\"RGB\").save(img1_path)\n",
    "        img2.convert(\"RGB\").save(img2_path)\n",
    "\n",
    "        analysis = DeepFace.verify(img1_path, img2_path, enforce_detection=False)\n",
    "        results['face_match'] = analysis['verified']\n",
    "        results['distance'] = analysis['distance']\n",
    "        results['success'] = True\n",
    "        results['message'] = 'Comparação facial concluída com DeepFace.'\n",
    "\n",
    "    except Exception as e:\n",
    "        results['message'] = f'Erro durante comparação facial: {e}'\n",
    "    finally:\n",
    "        try:\n",
    "            if os.path.exists(img1_path): os.remove(img1_path)\n",
    "            if os.path.exists(img2_path): os.remove(img2_path)\n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"[⚠] Erro ao remover arquivos temporários: {cleanup_error}\")\n",
    "    return results\n",
    "\n",
    "# --- Executa OCR ---\n",
    "ocr_data = perform_ocr_and_extract_data(img_documento_completo, provided_data)\n",
    "print(\"\\nResultado OCR:\")\n",
    "print(json.dumps(ocr_data, indent=4, ensure_ascii=False))\n",
    "\n",
    "# --- Executa comparação facial ---\n",
    "face_data = perform_face_comparison(img_documento_original, img_selfie)\n",
    "print(\"\\nResultado Reconhecimento Facial:\")\n",
    "print(json.dumps(face_data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f93b55c4ba59c",
   "metadata": {},
   "source": [
    "### 5. Feedback de Validação Final Combinado\n",
    "\n",
    "Esta função recebe os resultados das etapas anteriores e fornece um veredito final e feedback detalhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57438407d029bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def provide_final_validation_feedback(ocr_results, face_results):\n",
    "    \"\"\"\n",
    "    Combina os resultados do OCR/Dados e Reconhecimento Facial para dar o feedback final.\n",
    "\n",
    "    Args:\n",
    "        ocr_results (dict): Dicionário com resultados do OCR e comparação de dados.\n",
    "        face_results (dict): Dicionário com resultados da comparação facial.\n",
    "    \"\"\"\n",
    "    print(\"--- Resultado da Validação de Identidade ---\")\n",
    "\n",
    "    validation_status = \"Inválido\"\n",
    "    messages = []\n",
    "\n",
    "    # Avaliar resultados do OCR e Dados\n",
    "    if not ocr_results['success']:\n",
    "        messages.append(f\"Falha no processamento de dados do documento: {ocr_results['message']}\")\n",
    "    else:\n",
    "        if not ocr_results['name_match']:\n",
    "            messages.append(\"O nome extraído do documento NÃO confere com o nome fornecido.\")\n",
    "        if not ocr_results['cpf_match']:\n",
    "             messages.append(\"O CPF extraído do documento NÃO confere com o CPF fornecido.\")\n",
    "        if ocr_results['name_match'] and ocr_results['cpf_match']:\n",
    "             messages.append(\"Dados de Nome e CPF do documento conferem com os dados fornecidos.\")\n",
    "        elif ocr_results['success'] and not (ocr_results['name_match'] or ocr_results['cpf_match']):\n",
    "             messages.append(\"Nenhum dado chave (Nome, CPF) pôde ser confirmado a partir do documento ou não confere com os dados fornecidos.\")\n",
    "\n",
    "\n",
    "    # Avaliar resultados da Comparação Facial\n",
    "    if not face_results['success']:\n",
    "        messages.append(f\"Falha no processamento facial: {face_results['message']}\")\n",
    "    else:\n",
    "        if face_results['face_match']:\n",
    "            messages.append(f\"A face na selfie corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "        else:\n",
    "            messages.append(f\"A face na selfie NÃO corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "\n",
    "\n",
    "    # Determinar status final\n",
    "    # Condição para Válido: OCR processado com sucesso + Dados de Nome E CPF conferem + Comparação facial deu match\n",
    "    # Note: A lógica de validação pode ser ajustada conforme a regra de negócio.\n",
    "    # Aqui, exigimos match nos dados essenciais E match facial.\n",
    "    if ocr_results['success'] and ocr_results['name_match'] and ocr_results['cpf_match'] and face_results['success'] and face_results['face_match']:\n",
    "         validation_status = \"Válido\"\n",
    "         messages.append(\"Todas as verificações de identidade foram bem-sucedidas.\")\n",
    "    else:\n",
    "         validation_status = \"Inválido\"\n",
    "         messages.append(\"A validação de identidade falhou devido às inconsistências ou erros acima.\")\n",
    "\n",
    "\n",
    "    # --- Exibir o Feedback ---\n",
    "    print(f\"\\nSTATUS FINAL: {validation_status}\")\n",
    "    print(\"\\nDetalhes:\")\n",
    "    for msg in messages:\n",
    "        print(f\"- {msg}\")\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Executar a etapa de Feedback Final ---\n",
    "# Certifique-se de que ocr_data_results e face_comparison_results estão definidos\n",
    "if 'ocr_data_results' in locals() and 'face_comparison_results' in locals():\n",
    "     provide_final_validation_feedback(ocr_data_results, face_comparison_results)\n",
    "else:\n",
    "     print(\"Resultados das etapas anteriores (OCR e Reconhecimento Facial) não disponíveis.\")\n",
    "     print(\"Por favor, execute todas as células em ordem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e96c7714096a8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Integração com Redes Sociais (Simulada)</h3> </div>\n",
    "\n",
    "- **Linkagem de Contas:** Na ausência de integrações reais, simular o processo solicitando ao usuário os nomes de usuário ou perfis em redes sociais (Twitter, Facebook, Instagram). Criar células de código comentadas que demonstram como usar APIs (ex: `tweepy` para Twitter, `facebook-sdk` para Facebook) para conectar as contas.  \n",
    "- **Extração de Atividades Relacionadas a e-sports:** Para cada rede social simulada, mostrar como coletar dados relevantes: por exemplo, obter os últimos *tweets* do usuário e filtrar menções a e-sports ou FURIA; listar as páginas seguidas no Facebook com temas de gaming; ou verificar hashtags usadas em posts do Instagram. Usar `requests` e `BeautifulSoup` ou clientes de API para simulação. Armazenar essas informações em DataFrames para análise.  \n",
    "- **Monitoramento de Interações:** Demonstrar código que analisa curtidas, comentários ou retweets em publicações de e-sports (fingindo as permissões de API). Por exemplo, usar `tweepy` para buscar tweets que mencionem FURIA ou eventos de e-sports que o usuário retuitou ou comentou.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc903631095407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5023f63bcefe89",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Enriquecimento de Perfil com Dados Sociais e Multimídia</h3> </div>\n",
    "\n",
    "- **Análise de Comentários:** Para integrar comentários prévios do usuário no YouTube, Reddit e Twitter, incluir blocos que consumam APIs ou dados locais de análise anterior (supondo que existam). Usar `google-api-python-client` para extrair comentários de vídeos de e-sports do YouTube, `PRAW` para posts/comentários no Reddit, e `tweepy` ou dados simulados para tweets.  \n",
    "- **Processamento de Linguagem Natural:** Aplicar NLP para entender o perfil do usuário: usar bibliotecas como `transformers` ou `spaCy` para classificar sentimento, identificar tópicos ou palavras-chave frequentes nesses comentários. Por exemplo, gerar um gráfico de palavras-chave mais mencionadas em e-sports, ou uma análise de sentimento geral sobre jogos específicos.  \n",
    "- **Integração de Informações:** Combinar esses insights com os interesses declarados pelo usuário. Exibir visualmente (via `matplotlib` ou `seaborn`) uma nuvem de palavras ou gráfico que mostre as categorias de e-sports mais relevantes para o perfil (baseado em interesses + análise de comentários).  \n",
    "- **Perfis em Sites de e-Sports:** Permitir que o usuário insira links para seus perfis em plataformas de e-sports (como GameBattles, HLTV, Liquipedia). Usar `requests` e `BeautifulSoup` para raspar detalhes do perfil (jogos, histórico de partidas). Em seguida, aplicar um modelo de IA (ex: `transformers` BERT) para classificar se o conteúdo textual do perfil é relevante às preferências do usuário (por exemplo, buscando termos de jogos citados pelo usuário). Mostrar se há “match” entre interesses do usuário e informações do perfil scraped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc151832ad30fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e65090fbbfcb5a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Estruturação do Notebook</h3> </div>\n",
    "\n",
    "- Organizar o notebook em seções claras conforme as etapas acima: **Coleta de Dados**, **Validação de Identidade**, **Integração de Redes Sociais**, **Enriquecimento com Dados Sociais**, **Conclusão**.  \n",
    "- Incluir explicações breves em cada seção usando células Markdown, resumindo o objetivo daquela etapa. Combinar descrições em texto com células de código demonstrativas.  \n",
    "- Sugerir bibliotecas específicas no contexto de cada etapa: por exemplo, mencionar `ipywidgets` ou `streamlit` na coleta de dados, `pytesseract`/`OpenCV` na validação de documentos, `tweepy`/`PRAW`/`BeautifulSoup` na integração social, e `transformers`/`spaCy` na análise de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255b8c4d4857ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfadd7aa567531f2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Dicas de Apresentação do Protótipo</h3> </div>\n",
    "\n",
    "- **Formatação Atraente:** Usar cabeçalhos (`#`, `##`), listas e imagens (logotipos de e-sports, ícones de redes sociais) para tornar o notebook visualmente agradável. Células Markdown bem elaboradas ajudam na legibilidade.  \n",
    "- **Interatividade:** Incluir elementos interativos (sliders, botões de upload, caixas de seleção) via `ipywidgets` para simular um fluxo real de uso. Isso torna a demonstração dinâmica mesmo no ambiente de notebook.  \n",
    "- **Visualização de Dados:** Aproveitar gráficos (matplotlib, seaborn ou plotly) para mostrar perfis de interesse ou resultados das análises de comentários. Um gráfico de barras ou nuvem de palavras torna o conteúdo mais didático.  \n",
    "- **Narração do Código:** Inserir comentários explicativos e outputs de exemplo que guiem o avaliador pelo processo passo a passo. Ao final, apresentar um breve resumo dos resultados obtidos para evidenciar que todos os requisitos foram atendidos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37fafd0bfde477",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Conclusão</h3> </div>\n",
    "\n",
    "Este plano garante uma implementação completa dos requisitos do desafio, integrando coleta de informações pessoais e de interesse em e-sports, validação de identidade baseada em IA, simulação de integração social e enriquecimento de perfil com dados externos. A organização em seções claras, o uso de bibliotecas especializadas (ex: **Streamlit/ipywidgets** para interfaces, **OpenCV/face_recognition** para validação, **transformers/spaCy** para IA, **pandas** para dados) e as sugestões de apresentação asseguram uma entrega alinhada e de fácil acompanhamento, mesmo no formato de notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

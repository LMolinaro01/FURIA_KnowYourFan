{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"text-align: center;\"> <h1> FURIA Know Your Fan </h1> </div>",
   "id": "71cbc009a6d1ea09"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3> Todos os pip, ferramentas e bibliotecas utilizadas </h3> </div>\n",
    "\n",
    "- pip install python-dotenv ipywidgets cryptography"
   ],
   "id": "ef80bf6c08fb5459"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"text-align: center;\"> <h3> Chave API Oculta (Arquivo .env) </h3> </div>",
   "id": "964ac0276a6352a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar variáveis do .env\n",
    "load_dotenv()\n",
    "\n",
    "chave_api = os.getenv('API_KEY')"
   ],
   "id": "b7ba830f86466a8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Coleta de Dados Básicos e Interesses Relacionados à FURIA</h3> </div>\n",
    "  \n",
    "- **Formulário Inicial:** Criar um formulário em Jupyter Notebook (usando `ipywidgets` ou `Streamlit`) para capturar dados pessoais fundamentais: nome, CPF, endereço, data de nascimento, email etc. Validar formato de CPF (biblioteca `python-bcpf` ou validação via regex) e outros campos para evitar erros de digitação.  \n",
    "\n",
    "- **Interesses e Atividades em e-sports:** Incluir no notebook seções ou perguntas interativas sobre interesses em e-sports, times preferidos (FURIA), jogos mais acompanhados, frequência de eventos assistidos, ingressos ou periféricos adquiridos no último ano. Utilizar `pandas` para estruturar as respostas em um DataFrame. Poder-se-á simular coleta de dados de APIs públicas de eventos (por exemplo, dados de torneios CS:GO) ou pedir ao usuário que importe seu histórico (como um CSV de compras) para preencher esse perfil de maneira realista.  \n",
    "\n",
    "- **Compras Relacionadas:** Se for aplicável, permitir o upload de extratos simplificados ou listas de compras (como merch de teams e-sports). Usar `pandas` ou `openpyxl` para ler esses arquivos e filtrar itens de interesse (palavras-chave relacionadas a jogos, marcas de e-sports, etc)."
   ],
   "id": "12aac8180eeb5b5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Validação de Identidade com Abordagem de IA</h3> </div>\n",
    "\n",
    "- **Upload de Documentos:** Incluir um widget de upload de arquivos de imagem (RG, CNH ou passaporte) e, opcionalmente, uma selfie do usuário.  \n",
    "- **OCR e Extração de Dados:** Utilizar uma biblioteca de OCR como `pytesseract` ou `easyocr` para extrair texto do documento. Comparar nome e CPF extraídos com os dados básicos fornecidos para consistência.  \n",
    "- **Reconhecimento Facial:** Para fortalecer a validação, aplicar uma técnica de reconhecimento facial simples. Usar bibliotecas como `face_recognition` ou `OpenCV` com modelos pré-treinados para detectar rostos na selfie e na foto do documento, e então verificar se pertencem à mesma pessoa (por exemplo, comparando descritores faciais).  \n",
    "- **Feedback de Validação:** Exibir no notebook resultados da validação (válido/inválido) com base na correspondência de texto e face. Fornecer mensagens orientativas caso haja inconsistências (ex: “CPF não confere com o documento enviado”)."
   ],
   "id": "ca6996e942e24f04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Instale as bibliotecas necessárias\n",
    "\n",
    "- pytesseract (requer Tesseract OCR engine instalado separadamente)\n",
    " \n",
    "- Pillow (dependência do pytesseract)\n",
    " \n",
    "- face_recognition (requer dlib, pode ser complexo instalar em alguns sistemas)\n",
    "\n",
    "- ipywidgets (para o widget de upload)\n",
    "\n",
    "<br>\n",
    "\n",
    "```pip install pytesseract Pillow face_recognition ipywidgets ```\n"
   ],
   "id": "64ed12b2bdcdbcf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Preparação e Upload de Documentos\n",
    "\n",
    "Começamos pedindo ao usuário para carregar os arquivos necessários via widget. Precisaremos da imagem do documento completo para OCR e extração de dados, e possivelmente uma imagem separada da foto do documento e uma selfie para reconhecimento facial. Vamos criar widgets separados para clareza."
   ],
   "id": "e4d3f778faa45d99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Widgets de Upload\n",
    "print(\"--- Upload de Documentos ---\")\n",
    "\n",
    "print(\"\\nPor favor, carregue a IMAGEM COMPLETA do documento (RG, CNH, Passaporte):\")\n",
    "uploader_documento_completo = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False\n",
    ")\n",
    "display(uploader_documento_completo)\n",
    "\n",
    "print(\"\\nPor favor, carregue a IMAGEM SOMENTE da FOTO presente no documento:\")\n",
    "uploader_foto_documento = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False\n",
    ")\n",
    "display(uploader_foto_documento)\n",
    "\n",
    "print(\"\\nPor favor, carregue sua SELFIE:\")\n",
    "uploader_selfie = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False\n",
    ")\n",
    "display(uploader_selfie)\n",
    "\n",
    "print(\"\\nCarregue os arquivos usando os botões acima. As próximas etapas processarão os arquivos carregados.\")\n",
    "\n",
    "# Variáveis para armazenar as imagens PIL carregadas\n",
    "img_documento_completo = None\n",
    "img_foto_documento = None\n",
    "img_selfie = None\n",
    "\n",
    "# Função para carregar uma imagem de um widget de upload\n",
    "def load_image_from_widget(uploader_widget):\n",
    "    if uploader_widget.value:\n",
    "        # Pega o primeiro arquivo (multiple=False)\n",
    "        uploaded_file_info = uploader_widget.value[next(iter(uploader_widget.value))]\n",
    "        file_content = uploaded_file_info['content']\n",
    "        try:\n",
    "            img = Image.open(io.BytesIO(file_content))\n",
    "            print(f\"'{uploaded_file_info['metadata']['name']}' carregado com sucesso.\")\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao abrir a imagem '{uploaded_file_info['metadata']['name']}': {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Nenhum arquivo carregado no widget.\")\n",
    "        return None"
   ],
   "id": "6a27da3aaf349460"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Processar Uploads e Preparar Imagens\n",
    "\n",
    "Execute esta célula depois que todos os arquivos foram carregados nos widgets acima."
   ],
   "id": "e444dee6b1a2ab62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"--- Processando Imagens Carregadas ---\")\n",
    "clear_output(wait=True) # Limpa a saída anterior dos widgets para organização\n",
    "\n",
    "# Carregar as imagens usando a função auxiliar\n",
    "img_documento_completo = load_image_from_widget(uploader_documento_completo)\n",
    "img_foto_documento = load_image_from_widget(uploader_foto_documento)\n",
    "img_selfie = load_image_from_widget(uploader_selfie)\n",
    "\n",
    "# Verificar se as imagens essenciais foram carregadas\n",
    "if img_documento_completo and img_foto_documento and img_selfie:\n",
    "    print(\"\\nTodas as imagens essenciais foram carregadas. Próximas etapas: OCR e Reconhecimento Facial.\")\n",
    "    # Opcional: Exibir miniaturas das imagens carregadas para confirmação\n",
    "    # from IPython.display import display as display_image\n",
    "    # print(\"\\nVisualização rápida:\")\n",
    "    # display_image(img_documento_completo.resize((100, int(100 * img_documento_completo.size[1] / img_documento_completo.size[0]))))\n",
    "    # display_image(img_foto_documento.resize((100, int(100 * img_foto_documento.size[1] / img_foto_documento.size[0]))))\n",
    "    # display_image(img_selfie.resize((100, int(100 * img_selfie.size[1] / img_selfie.size[0]))))\n",
    "\n",
    "else:\n",
    "    print(\"\\nErro: Nem todas as imagens necessárias foram carregadas. Por favor, carregue todos os arquivos usando os widgets na célula anterior.\")"
   ],
   "id": "e22357c1098780d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. OCR, Extração e Comparação de Dados Textuais\n",
    "\n",
    "Definimos uma função para realizar o OCR na imagem do documento completo, extrair o texto, tentar encontrar Nome e CPF e compará-los com dados fornecidos (vamos simular esses dados fornecidos para o exemplo)."
   ],
   "id": "f51e06c15ea2efa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pytesseract\n",
    "import re # Para regex, útil na extração de dados\n",
    "\n",
    "# --- Configuração do pytesseract (ajuste o caminho se necessário) ---\n",
    "# Em alguns sistemas (especialmente Windows), você pode precisar apontar\n",
    "# para o executável do Tesseract. Ex:\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# --- Dados fornecidos pelo usuário (simulados) ---\n",
    "# Em um cenário real, estes viriam de um formulário anterior ou API\n",
    "provided_data = {\n",
    "    \"nome\": \"Nome Completo do Usuário\", # Substitua pelo nome real esperado\n",
    "    \"cpf\": \"123.456.789-00\"           # Substitua pelo CPF real esperado (pode estar formatado ou não)\n",
    "}\n",
    "\n",
    "def clean_cpf(cpf_str):\n",
    "    \"\"\"Remove pontos e traços de uma string de CPF.\"\"\"\n",
    "    if isinstance(cpf_str, str):\n",
    "        return cpf_str.replace('.', '').replace('-', '').strip()\n",
    "    return \"\"\n",
    "\n",
    "def perform_ocr_and_extract_data(pil_image, provided_user_data):\n",
    "    \"\"\"\n",
    "    Realiza OCR na imagem do documento, extrai texto, tenta encontrar Nome e CPF\n",
    "    e compara com dados fornecidos.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Resultados da extração e comparação ({'extracted_text', 'extracted_name', 'extracted_cpf', 'name_match', 'cpf_match', 'success'})\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'extracted_text': None,\n",
    "        'extracted_name': None,\n",
    "        'extracted_cpf': None,\n",
    "        'name_match': False,\n",
    "        'cpf_match': False,\n",
    "        'success': False, # Indica se o OCR e a extração foram bem-sucedidos\n",
    "        'message': 'Processamento de dados textuais pendente.'\n",
    "    }\n",
    "\n",
    "    if pil_image is None:\n",
    "        results['message'] = 'Erro: Imagem do documento completo não fornecida para OCR.'\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        # 1. Realizar OCR\n",
    "        print(\"Realizando OCR na imagem do documento...\")\n",
    "        extracted_text = pytesseract.image_to_string(pil_image, lang='por') # Ajuste 'lang' se necessário\n",
    "        results['extracted_text'] = extracted_text\n",
    "        print(\"OCR concluído. Tentando extrair dados...\")\n",
    "\n",
    "        # 2. Tentar extrair Nome e CPF do texto (lógica simplificada)\n",
    "        # Esta parte é complexa e depende muito do layout do documento.\n",
    "        # Regex ou NLP mais avançado seria necessário para robustez.\n",
    "        # Exemplo simplificado: Buscar por padrões de CPF\n",
    "        cpf_match_ocr = re.search(r'\\d{2,3}\\.?\\d{3}\\.?\\d{3}-?\\d{2}', extracted_text)\n",
    "        if cpf_match_ocr:\n",
    "            results['extracted_cpf'] = cpf_match_ocr.group(0)\n",
    "\n",
    "        # Extração de nome é mais difícil sem estrutura fixa.\n",
    "        # Poderíamos tentar encontrar o nome perto do CPF ou em linhas específicas,\n",
    "        # mas vamos manter simples por agora, apenas usando o CPF extraído.\n",
    "\n",
    "        results['success'] = True # OCR e extração básica foram bem-sucedidos\n",
    "        results['message'] = 'OCR e extração básica concluídos.'\n",
    "\n",
    "\n",
    "        # 3. Comparar com dados fornecidos pelo usuário\n",
    "        provided_name = provided_user_data.get(\"nome\", \"\")\n",
    "        provided_cpf = provided_user_data.get(\"cpf\", \"\")\n",
    "\n",
    "        # Comparar Nome (case-insensitive)\n",
    "        if extracted_text and provided_name: # Só compara se houver texto e nome fornecido\n",
    "             # A comparação de nome a partir de texto bruto é imprecisa.\n",
    "             # Uma forma muito básica seria verificar se partes do nome fornecido estão no texto extraído.\n",
    "             # Exemplo: verificar se o primeiro e último nome fornecidos estão no texto.\n",
    "             provided_name_parts = provided_name.strip().lower().split()\n",
    "             if len(provided_name_parts) >= 2:\n",
    "                 first_name = provided_name_parts[0]\n",
    "                 last_name = provided_name_parts[-1]\n",
    "                 if first_name in extracted_text.lower() and last_name in extracted_text.lower():\n",
    "                      results['name_match'] = True\n",
    "                      print(\"Comparação de Nome (simplificada): Nome parcial encontrado no texto.\")\n",
    "                 else:\n",
    "                     print(\"Comparação de Nome (simplificada): Nome parcial NÃO encontrado no texto.\")\n",
    "             else:\n",
    "                 # Tentativa mais simples: verificar se o nome completo (exato) está no texto\n",
    "                 if provided_name.strip().lower() in extracted_text.lower():\n",
    "                     results['name_match'] = True\n",
    "                     print(\"Comparação de Nome (exata): Nome completo encontrado no texto.\")\n",
    "                 else:\n",
    "                     print(\"Comparação de Nome (exata): Nome completo NÃO encontrado no texto.\")\n",
    "\n",
    "        elif provided_name:\n",
    "             print(\"Comparação de Nome: Não foi possível extrair texto suficiente para comparar.\")\n",
    "             results['name_match'] = False # Não há como comparar se não extraiu texto\n",
    "\n",
    "        # Comparar CPF (limpando formatação)\n",
    "        if results['extracted_cpf'] and provided_cpf:\n",
    "            cleaned_extracted_cpf = clean_cpf(results['extracted_cpf'])\n",
    "            cleaned_provided_cpf = clean_cpf(provided_cpf)\n",
    "            results['cpf_match'] = (cleaned_extracted_cpf == cleaned_provided_cpf)\n",
    "            print(f\"Comparação de CPF: Extraído '{cleaned_extracted_cpf}' vs Fornecido '{cleaned_provided_cpf}' -> Confere: {results['cpf_match']}\")\n",
    "        elif provided_cpf:\n",
    "             print(\"Comparação de CPF: Não foi possível extrair um padrão de CPF do documento para comparar.\")\n",
    "             results['cpf_match'] = False # Não há como comparar se não extraiu CPF\n",
    "\n",
    "\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        results['message'] = \"Erro: Tesseract OCR engine não encontrado. Instale o Tesseract e ajuste a configuração se necessário.\"\n",
    "        results['success'] = False\n",
    "        print(results['message'])\n",
    "    except Exception as e:\n",
    "        results['message'] = f\"Erro durante o OCR ou extração: {e}\"\n",
    "        results['success'] = False\n",
    "        print(results['message'])\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Executar a etapa de OCR e Comparação de Dados ---\n",
    "# Certifique-se de que img_documento_completo e provided_data estão definidos antes de executar\n",
    "if 'img_documento_completo' in locals() and img_documento_completo is not None:\n",
    "    ocr_data_results = perform_ocr_and_extract_data(img_documento_completo, provided_data)\n",
    "    print(\"\\n--- Resultados da Etapa de OCR e Dados ---\")\n",
    "    print(f\"Status: {'Sucesso' if ocr_data_results['success'] else 'Falha'}\")\n",
    "    print(f\"Mensagem: {ocr_data_results['message']}\")\n",
    "    if ocr_data_results['success']:\n",
    "        print(f\"Texto Bruto Extraído (parcial): {ocr_data_results['extracted_text'][:200]}...\") # Mostra só o começo\n",
    "        print(f\"Nome Encontrado (OCR): {ocr_data_results['extracted_name']}\")\n",
    "        print(f\"CPF Encontrado (OCR): {ocr_data_results['extracted_cpf']}\")\n",
    "        print(f\"Nome Confere com Fornecido: {ocr_data_results['name_match']}\")\n",
    "        print(f\"CPF Confere com Fornecido: {ocr_data_results['cpf_match']}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "else:\n",
    "    print(\"A imagem do documento completo não foi carregada. Execute a(s) célula(s) de upload primeiro.\")\n",
    "    ocr_data_results = {'success': False, 'message': 'Imagem do documento completo não carregada.'} # Define um resultado padrão em caso de falha"
   ],
   "id": "c82efa4ee6dc53ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Reconhecimento e Comparação Facial\n",
    "\n",
    "Agora, definimos uma função para lidar com a comparação facial entre a foto do documento e a selfie"
   ],
   "id": "841cb67ef57bd894"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "def perform_face_comparison(img_documento_foto, img_selfie_foto):\n",
    "    \"\"\"\n",
    "    Compara a face na foto do documento com a face na selfie.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Resultados da comparação facial ({'face_match', 'distance', 'success', 'message'})\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'face_match': False,\n",
    "        'distance': None,\n",
    "        'success': False, # Indica se o processo de comparação ocorreu sem erros graves\n",
    "        'message': 'Comparação facial pendente.'\n",
    "    }\n",
    "\n",
    "    if img_documento_foto is None or img_selfie_foto is None:\n",
    "        results['message'] = 'Erro: Imagens da foto do documento e/ou selfie não fornecidas para comparação facial.'\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        print(\"Iniciando comparação facial...\")\n",
    "\n",
    "        # Converter imagens PIL para array numpy (face_recognition trabalha com numpy)\n",
    "        img_doc_np = np.array(img_documento_foto.convert('RGB'))\n",
    "        img_selfie_np = np.array(img_selfie_foto.convert('RGB'))\n",
    "\n",
    "\n",
    "        # Encontrar os 'encodings' (características únicas) das faces\n",
    "        print(\"Extraindo encodings da foto do documento...\")\n",
    "        document_face_encodings = face_recognition.face_encodings(img_doc_np)\n",
    "\n",
    "        print(\"Extraindo encodings da selfie...\")\n",
    "        selfie_face_encodings = face_recognition.face_encodings(img_selfie_np)\n",
    "\n",
    "        if not document_face_encodings:\n",
    "            results['message'] = \"Erro: Não foi possível detectar um rosto na foto do documento.\"\n",
    "            print(results['message'])\n",
    "            return results\n",
    "        if not selfie_face_encodings:\n",
    "            results['message'] = \"Erro: Não foi possível detectar um rosto na selfie.\"\n",
    "            print(results['message'])\n",
    "            return results\n",
    "\n",
    "        # Comparar o primeiro rosto encontrado em cada imagem\n",
    "        known_face_encoding = document_face_encodings[0]\n",
    "        unknown_face_encoding = selfie_face_encodings[0]\n",
    "\n",
    "        # Comparar faces. Retorna True se for um match (abaixo de um limiar interno, padrão 0.6)\n",
    "        results['face_match'] = face_recognition.compare_faces([known_face_encoding], unknown_face_encoding)[0]\n",
    "\n",
    "        # Calcular a distância facial. Menor distância = maior similaridade.\n",
    "        # O limiar de 0.6 mencionado antes é a distância padrão para `compare_faces`.\n",
    "        results['distance'] = face_recognition.face_distance([known_face_encoding], unknown_face_encoding)[0]\n",
    "\n",
    "        results['success'] = True\n",
    "        results['message'] = 'Comparação facial concluída.'\n",
    "        print(results['message'])\n",
    "\n",
    "    except Exception as e:\n",
    "        results['message'] = f\"Erro durante o reconhecimento facial: {e}\"\n",
    "        results['success'] = False\n",
    "        print(results['message'])\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Executar a etapa de Comparação Facial ---\n",
    "# Certifique-se de que img_foto_documento e img_selfie estão definidos antes de executar\n",
    "if 'img_foto_documento' in locals() and 'img_selfie' in locals() and img_foto_documento is not None and img_selfie is not None:\n",
    "     face_comparison_results = perform_face_comparison(img_foto_documento, img_selfie)\n",
    "     print(\"\\n--- Resultados da Etapa de Reconhecimento Facial ---\")\n",
    "     print(f\"Status: {'Sucesso' if face_comparison_results['success'] else 'Falha no Processo'}\")\n",
    "     print(f\"Mensagem do Processo: {face_comparison_results['message']}\")\n",
    "     if face_comparison_results['success']:\n",
    "        print(f\"Resultado da Comparação (Match): {face_comparison_results['face_match']}\")\n",
    "        print(f\"Distância Facial: {face_comparison_results['distance']:.4f} (Menor é mais similar. Limiar padrão ~0.6)\")\n",
    "     print(\"-------------------------------------------------\")\n",
    "\n",
    "elif 'img_foto_documento' not in locals() or img_foto_documento is None:\n",
    "    print(\"A imagem da foto do documento não foi carregada. Execute a(s) célula(s) de upload primeiro.\")\n",
    "    face_comparison_results = {'success': False, 'message': 'Imagem da foto do documento não carregada.'}\n",
    "elif 'img_selfie' not in locals() or img_selfie is None:\n",
    "     print(\"A imagem da selfie não foi carregada. Execute a(s) célula(s) de upload primeiro.\")\n",
    "     face_comparison_results = {'success': False, 'message': 'Imagem da selfie não carregada.'}\n",
    "else:\n",
    "     print(\"Imagens necessárias para reconhecimento facial não foram carregadas. Execute a(s) célula(s) de upload primeiro.\")\n",
    "     face_comparison_results = {'success': False, 'message': 'Imagens essenciais não carregadas.'}"
   ],
   "id": "28720deba99a0584",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Feedback de Validação Final Combinado\n",
    "\n",
    "Esta função recebe os resultados das etapas anteriores e fornece um veredito final e feedback detalhado."
   ],
   "id": "500f93b55c4ba59c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def provide_final_validation_feedback(ocr_results, face_results):\n",
    "    \"\"\"\n",
    "    Combina os resultados do OCR/Dados e Reconhecimento Facial para dar o feedback final.\n",
    "\n",
    "    Args:\n",
    "        ocr_results (dict): Dicionário com resultados do OCR e comparação de dados.\n",
    "        face_results (dict): Dicionário com resultados da comparação facial.\n",
    "    \"\"\"\n",
    "    print(\"--- Resultado da Validação de Identidade ---\")\n",
    "\n",
    "    validation_status = \"Inválido\"\n",
    "    messages = []\n",
    "\n",
    "    # Avaliar resultados do OCR e Dados\n",
    "    if not ocr_results['success']:\n",
    "        messages.append(f\"Falha no processamento de dados do documento: {ocr_results['message']}\")\n",
    "    else:\n",
    "        if not ocr_results['name_match']:\n",
    "            messages.append(\"O nome extraído do documento NÃO confere com o nome fornecido.\")\n",
    "        if not ocr_results['cpf_match']:\n",
    "             messages.append(\"O CPF extraído do documento NÃO confere com o CPF fornecido.\")\n",
    "        if ocr_results['name_match'] and ocr_results['cpf_match']:\n",
    "             messages.append(\"Dados de Nome e CPF do documento conferem com os dados fornecidos.\")\n",
    "        elif ocr_results['success'] and not (ocr_results['name_match'] or ocr_results['cpf_match']):\n",
    "             messages.append(\"Nenhum dado chave (Nome, CPF) pôde ser confirmado a partir do documento ou não confere com os dados fornecidos.\")\n",
    "\n",
    "\n",
    "    # Avaliar resultados da Comparação Facial\n",
    "    if not face_results['success']:\n",
    "        messages.append(f\"Falha no processamento facial: {face_results['message']}\")\n",
    "    else:\n",
    "        if face_results['face_match']:\n",
    "            messages.append(f\"A face na selfie corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "        else:\n",
    "            messages.append(f\"A face na selfie NÃO corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "\n",
    "\n",
    "    # Determinar status final\n",
    "    # Condição para Válido: OCR processado com sucesso + Dados de Nome E CPF conferem + Comparação facial deu match\n",
    "    # Note: A lógica de validação pode ser ajustada conforme a regra de negócio.\n",
    "    # Aqui, exigimos match nos dados essenciais E match facial.\n",
    "    if ocr_results['success'] and ocr_results['name_match'] and ocr_results['cpf_match'] and face_results['success'] and face_results['face_match']:\n",
    "         validation_status = \"Válido\"\n",
    "         messages.append(\"Todas as verificações de identidade foram bem-sucedidas.\")\n",
    "    else:\n",
    "         validation_status = \"Inválido\"\n",
    "         messages.append(\"A validação de identidade falhou devido às inconsistências ou erros acima.\")\n",
    "\n",
    "\n",
    "    # --- Exibir o Feedback ---\n",
    "    print(f\"\\nSTATUS FINAL: {validation_status}\")\n",
    "    print(\"\\nDetalhes:\")\n",
    "    for msg in messages:\n",
    "        print(f\"- {msg}\")\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Executar a etapa de Feedback Final ---\n",
    "# Certifique-se de que ocr_data_results e face_comparison_results estão definidos\n",
    "if 'ocr_data_results' in locals() and 'face_comparison_results' in locals():\n",
    "     provide_final_validation_feedback(ocr_data_results, face_comparison_results)\n",
    "else:\n",
    "     print(\"Resultados das etapas anteriores (OCR e Reconhecimento Facial) não disponíveis.\")\n",
    "     print(\"Por favor, execute todas as células em ordem.\")"
   ],
   "id": "c57438407d029bd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Integração com Redes Sociais (Simulada)</h3> </div>\n",
    "\n",
    "- **Linkagem de Contas:** Na ausência de integrações reais, simular o processo solicitando ao usuário os nomes de usuário ou perfis em redes sociais (Twitter, Facebook, Instagram). Criar células de código comentadas que demonstram como usar APIs (ex: `tweepy` para Twitter, `facebook-sdk` para Facebook) para conectar as contas.  \n",
    "- **Extração de Atividades Relacionadas a e-sports:** Para cada rede social simulada, mostrar como coletar dados relevantes: por exemplo, obter os últimos *tweets* do usuário e filtrar menções a e-sports ou FURIA; listar as páginas seguidas no Facebook com temas de gaming; ou verificar hashtags usadas em posts do Instagram. Usar `requests` e `BeautifulSoup` ou clientes de API para simulação. Armazenar essas informações em DataFrames para análise.  \n",
    "- **Monitoramento de Interações:** Demonstrar código que analisa curtidas, comentários ou retweets em publicações de e-sports (fingindo as permissões de API). Por exemplo, usar `tweepy` para buscar tweets que mencionem FURIA ou eventos de e-sports que o usuário retuitou ou comentou.  "
   ],
   "id": "9d2e96c7714096a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f9dc903631095407",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Enriquecimento de Perfil com Dados Sociais e Multimídia</h3> </div>\n",
    "\n",
    "- **Análise de Comentários:** Para integrar comentários prévios do usuário no YouTube, Reddit e Twitter, incluir blocos que consumam APIs ou dados locais de análise anterior (supondo que existam). Usar `google-api-python-client` para extrair comentários de vídeos de e-sports do YouTube, `PRAW` para posts/comentários no Reddit, e `tweepy` ou dados simulados para tweets.  \n",
    "- **Processamento de Linguagem Natural:** Aplicar NLP para entender o perfil do usuário: usar bibliotecas como `transformers` ou `spaCy` para classificar sentimento, identificar tópicos ou palavras-chave frequentes nesses comentários. Por exemplo, gerar um gráfico de palavras-chave mais mencionadas em e-sports, ou uma análise de sentimento geral sobre jogos específicos.  \n",
    "- **Integração de Informações:** Combinar esses insights com os interesses declarados pelo usuário. Exibir visualmente (via `matplotlib` ou `seaborn`) uma nuvem de palavras ou gráfico que mostre as categorias de e-sports mais relevantes para o perfil (baseado em interesses + análise de comentários).  \n",
    "- **Perfis em Sites de e-Sports:** Permitir que o usuário insira links para seus perfis em plataformas de e-sports (como GameBattles, HLTV, Liquipedia). Usar `requests` e `BeautifulSoup` para raspar detalhes do perfil (jogos, histórico de partidas). Em seguida, aplicar um modelo de IA (ex: `transformers` BERT) para classificar se o conteúdo textual do perfil é relevante às preferências do usuário (por exemplo, buscando termos de jogos citados pelo usuário). Mostrar se há “match” entre interesses do usuário e informações do perfil scraped.  "
   ],
   "id": "de5023f63bcefe89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "11cc151832ad30fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Estruturação do Notebook</h3> </div>\n",
    "\n",
    "- Organizar o notebook em seções claras conforme as etapas acima: **Coleta de Dados**, **Validação de Identidade**, **Integração de Redes Sociais**, **Enriquecimento com Dados Sociais**, **Conclusão**.  \n",
    "- Incluir explicações breves em cada seção usando células Markdown, resumindo o objetivo daquela etapa. Combinar descrições em texto com células de código demonstrativas.  \n",
    "- Sugerir bibliotecas específicas no contexto de cada etapa: por exemplo, mencionar `ipywidgets` ou `streamlit` na coleta de dados, `pytesseract`/`OpenCV` na validação de documentos, `tweepy`/`PRAW`/`BeautifulSoup` na integração social, e `transformers`/`spaCy` na análise de linguagem."
   ],
   "id": "54e65090fbbfcb5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b255b8c4d4857ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Dicas de Apresentação do Protótipo</h3> </div>\n",
    "\n",
    "- **Formatação Atraente:** Usar cabeçalhos (`#`, `##`), listas e imagens (logotipos de e-sports, ícones de redes sociais) para tornar o notebook visualmente agradável. Células Markdown bem elaboradas ajudam na legibilidade.  \n",
    "- **Interatividade:** Incluir elementos interativos (sliders, botões de upload, caixas de seleção) via `ipywidgets` para simular um fluxo real de uso. Isso torna a demonstração dinâmica mesmo no ambiente de notebook.  \n",
    "- **Visualização de Dados:** Aproveitar gráficos (matplotlib, seaborn ou plotly) para mostrar perfis de interesse ou resultados das análises de comentários. Um gráfico de barras ou nuvem de palavras torna o conteúdo mais didático.  \n",
    "- **Narração do Código:** Inserir comentários explicativos e outputs de exemplo que guiem o avaliador pelo processo passo a passo. Ao final, apresentar um breve resumo dos resultados obtidos para evidenciar que todos os requisitos foram atendidos.  "
   ],
   "id": "bfadd7aa567531f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\"> <h3>Conclusão</h3> </div>\n",
    "\n",
    "Este plano garante uma implementação completa dos requisitos do desafio, integrando coleta de informações pessoais e de interesse em e-sports, validação de identidade baseada em IA, simulação de integração social e enriquecimento de perfil com dados externos. A organização em seções claras, o uso de bibliotecas especializadas (ex: **Streamlit/ipywidgets** para interfaces, **OpenCV/face_recognition** para validação, **transformers/spaCy** para IA, **pandas** para dados) e as sugestões de apresentação asseguram uma entrega alinhada e de fácil acompanhamento, mesmo no formato de notebook."
   ],
   "id": "ab37fafd0bfde477"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cbc009a6d1ea09",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h1> FURIA Know Your Fan </h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80bf6c08fb5459",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3> Todos os pip, ferramentas e bibliotecas utilizadas </h3> </div>\n",
    "\n",
    "- pip install python-dotenv ipywidgets cryptography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ac0276a6352a1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3> Chave API Oculta (Arquivo .env) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba830f86466a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar variáveis do .env\n",
    "load_dotenv()\n",
    "\n",
    "chave_api = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aac8180eeb5b5c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Coleta de Dados Básicos e Interesses Relacionados à FURIA</h3> </div>\n",
    "  \n",
    "- **Formulário Inicial:** Criar um formulário em Jupyter Notebook (usando `ipywidgets` ou `Streamlit`) para capturar dados pessoais fundamentais: nome, CPF, endereço, data de nascimento, email etc. Validar formato de CPF (biblioteca `python-bcpf` ou validação via regex) e outros campos para evitar erros de digitação.  \n",
    "\n",
    "- **Interesses e Atividades em e-sports:** Incluir no notebook seções ou perguntas interativas sobre interesses em e-sports, times preferidos (FURIA), jogos mais acompanhados, frequência de eventos assistidos, ingressos ou periféricos adquiridos no último ano. Utilizar `pandas` para estruturar as respostas em um DataFrame. Poder-se-á simular coleta de dados de APIs públicas de eventos (por exemplo, dados de torneios CS:GO) ou pedir ao usuário que importe seu histórico (como um CSV de compras) para preencher esse perfil de maneira realista.  \n",
    "\n",
    "- **Compras Relacionadas:** Se for aplicável, permitir o upload de extratos simplificados ou listas de compras (como merch de teams e-sports). Usar `pandas` ou `openpyxl` para ler esses arquivos e filtrar itens de interesse (palavras-chave relacionadas a jogos, marcas de e-sports, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dca973f7b28f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.server\n",
    "import socketserver\n",
    "import webbrowser\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "import hashlib\n",
    "import threading\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "PORT = 8080\n",
    "DATA_DIR = \"form_data\"\n",
    "KEY_FILE = \"rg_encryption.key\"\n",
    "\n",
    "# Carrega ou gera a chave de criptografia\n",
    "if not os.path.exists(KEY_FILE):\n",
    "    key = Fernet.generate_key()\n",
    "    with open(KEY_FILE, 'wb') as kf:\n",
    "        kf.write(key)\n",
    "else:\n",
    "    with open(KEY_FILE, 'rb') as kf:\n",
    "        key = kf.read()\n",
    "fernet = Fernet(key)\n",
    "\n",
    "class MyHandler(http.server.SimpleHTTPRequestHandler):\n",
    "    def do_POST(self):\n",
    "        # Só processa a rota '/submit'\n",
    "        if self.path != '/submit':\n",
    "            return super().do_GET()\n",
    "\n",
    "        # Lê o corpo da requisição como JSON\n",
    "        content_length = int(self.headers.get('Content-Length', 0))\n",
    "        raw_body = self.rfile.read(content_length).decode('utf-8')\n",
    "        try:\n",
    "            dados = json.loads(raw_body)\n",
    "        except json.JSONDecodeError:\n",
    "            self.send_error(400, \"Bad Request: JSON inválido\")\n",
    "            return\n",
    "\n",
    "        # Hash do CPF\n",
    "        cpf_original = dados.get('cpf')\n",
    "        if cpf_original:\n",
    "            dados['cpf'] = hashlib.sha256(cpf_original.encode('utf-8')).hexdigest()\n",
    "        else:\n",
    "            print(\"Aviso: 'cpf' não enviado.\")\n",
    "\n",
    "        # Extrai imagens em Base64 do JSON\n",
    "        rg_base64     = dados.pop('rgImagem_base64', None)\n",
    "        selfie_base64 = dados.pop('selfieImagem_base64', None)\n",
    "\n",
    "        # Adiciona timestamp de submissão\n",
    "        dados['submitted_at'] = datetime.utcnow().isoformat() + 'Z'\n",
    "\n",
    "        # Gera ID único e prepara diretório\n",
    "        user_id = str(uuid.uuid4())\n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "        # Criptografa e salva RG como arquivo .enc\n",
    "        if rg_base64:\n",
    "            try:\n",
    "                rg_bytes = base64.b64decode(rg_base64)\n",
    "                encrypted = fernet.encrypt(rg_bytes)\n",
    "                enc_filename = f\"{user_id}_rg.enc\"\n",
    "                enc_path = os.path.join(DATA_DIR, enc_filename)\n",
    "                with open(enc_path, 'wb') as ef:\n",
    "                    ef.write(encrypted)\n",
    "                dados['rgImagem_encrypted'] = enc_filename\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao criptografar/salvar RG: {e}\")\n",
    "\n",
    "        # Salva selfie como PNG (ou também criptografe se desejar)\n",
    "        if selfie_base64:\n",
    "            try:\n",
    "                selfie_bytes = base64.b64decode(selfie_base64)\n",
    "                selfie_filename = f\"{user_id}_selfie.png\"\n",
    "                selfie_path = os.path.join(DATA_DIR, selfie_filename)\n",
    "                with open(selfie_path, 'wb') as imgf:\n",
    "                    imgf.write(selfie_bytes)\n",
    "                dados['selfieImagem_file'] = selfie_filename\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao salvar Selfie: {e}\")\n",
    "\n",
    "        # Grava JSON de metadados de forma atômica\n",
    "        file_path = os.path.join(DATA_DIR, f\"{user_id}.json\")\n",
    "        temp_path = file_path + \".tmp\"\n",
    "        try:\n",
    "            with open(temp_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(dados, f, indent=4, ensure_ascii=False)\n",
    "            os.replace(temp_path, file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao salvar JSON: {e}\")\n",
    "            self.send_error(500, \"Internal Server Error: falha ao salvar dados\")\n",
    "            return\n",
    "\n",
    "        print(f\"Dados salvos (metadados + RG criptografado) em: {DATA_DIR}\")\n",
    "\n",
    "        # Envia resposta de sucesso\n",
    "        response = {\n",
    "            'status': 'success',\n",
    "            'message': 'Dados eviados e criptografados com sucesso!',\n",
    "            'user_id': user_id\n",
    "        }\n",
    "        self.send_response(200)\n",
    "        self.send_header('Content-Type', 'application/json')\n",
    "        self.end_headers()\n",
    "        self.wfile.write(json.dumps(response).encode('utf-8'))\n",
    "\n",
    "        # Desliga o servidor após 4 segundos\n",
    "        threading.Timer(4.0, self.server.shutdown).start()\n",
    "\n",
    "\n",
    "def run_server():\n",
    "    with socketserver.TCPServer((\"\", PORT), MyHandler) as httpd:\n",
    "        print(f\"Servidor rodando em http://localhost:{PORT}\")\n",
    "        webbrowser.open(f\"http://localhost:{PORT}/Form/form.html\")\n",
    "        httpd.serve_forever()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_server()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6996e942e24f04",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Validação de Identidade com Abordagem de IA</h3> </div>\n",
    "\n",
    "- **Upload de Documentos:** Incluir um widget de upload de arquivos de imagem (RG, CNH ou passaporte) e, opcionalmente, uma selfie do usuário.  \n",
    "- **OCR e Extração de Dados:** Utilizar uma biblioteca de OCR como `pytesseract` ou `easyocr` para extrair texto do documento. Comparar nome e CPF extraídos com os dados básicos fornecidos para consistência.  \n",
    "- **Reconhecimento Facial:** Para fortalecer a validação, aplicar uma técnica de reconhecimento facial simples. Usar bibliotecas como `face_recognition` ou `OpenCV` com modelos pré-treinados para detectar rostos na selfie e na foto do documento, e então verificar se pertencem à mesma pessoa (por exemplo, comparando descritores faciais).  \n",
    "- **Feedback de Validação:** Exibir no notebook resultados da validação (válido/inválido) com base na correspondência de texto e face. Fornecer mensagens orientativas caso haja inconsistências (ex: “CPF não confere com o documento enviado”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed12b2bdcdbcf6",
   "metadata": {},
   "source": [
    "### Instale as bibliotecas necessárias\n",
    "\n",
    "- pytesseract (requer Tesseract OCR engine instalado separadamente)\n",
    " \n",
    "- Pillow (dependência do pytesseract)\n",
    " \n",
    "- face_recognition (requer dlib, pode ser complexo instalar em alguns sistemas)\n",
    "\n",
    "- ipywidgets (para o widget de upload)\n",
    "\n",
    "<br>\n",
    "\n",
    "```pip install pytesseract Pillow face_recognition ipywidgets ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e06c15ea2efa4",
   "metadata": {},
   "source": [
    "OCR, Extração e Comparação de Dados Textuais\n",
    "\n",
    "Definimos uma função para realizar o OCR na imagem do documento completo, extrair o texto, tentar encontrar Nome e CPF e compará-los com dados fornecidos (vamos simular esses dados fornecidos para o exemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tesseract pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82efa4ee6dc53ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArquivo não encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Pré-processa e executa OCR\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m pre = preprocess_image(img_path)\n\u001b[32m     98\u001b[39m raw_text = ocr_with_boxes(pre)\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Extrai campos\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mpreprocess_image\u001b[39m\u001b[34m(img_path)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_image\u001b[39m(img_path):\n\u001b[32m     37\u001b[39m     img = cv2.imread(img_path)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# Deskew\u001b[39;00m\n\u001b[32m     41\u001b[39m     gray = deskew(gray)\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import pytesseract\n",
    "import re\n",
    "import hashlib\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "os.environ[\"TESSDATA_PREFIX\"] = R\"C:\\Program Files\\Tesseract-OCR\\tessdata\"\n",
    "pytesseract.pytesseract.tesseract_cmd = R\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "\n",
    "DATA_DIR = \"form_data\"\n",
    "KEY_FILE = \"rg_encryption.key\"\n",
    "\n",
    "# --- Carrega chave de criptografia ---\n",
    "with open(KEY_FILE, \"rb\") as f:\n",
    "    key = f.read()\n",
    "fernet = Fernet(key)\n",
    "\n",
    "# --- Recupera o último user_id automaticamente ---\n",
    "json_files = [f for f in os.listdir(DATA_DIR) if f.endswith(\".json\")]\n",
    "if not json_files:\n",
    "    raise FileNotFoundError(\"Nenhum arquivo JSON encontrado em 'form_data'.\")\n",
    "\n",
    "json_files.sort(key=lambda f: os.path.getmtime(os.path.join(DATA_DIR, f)), reverse=True)\n",
    "latest_json_path = os.path.join(DATA_DIR, json_files[0])\n",
    "user_id = os.path.splitext(json_files[0])[0]\n",
    "print(f\"[ℹ] Usando user_id: {user_id}\")\n",
    "\n",
    "# --- Lê JSON ---\n",
    "with open(latest_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    form_data = json.load(f)\n",
    "\n",
    "# --- Dados fornecidos pelo usuário ---\n",
    "provided_data = {\n",
    "    \"nome\": form_data.get(\"nome\", \"\"),\n",
    "    # CPF já vem como hash SHA-256\n",
    "    \"cpf_hash\": form_data.get(\"cpf\", \"\")\n",
    "}\n",
    "\n",
    "# --- Função de pré-processamento da imagem para OCR ---\n",
    "def preprocess_image(image):\n",
    "    image = image.convert(\"L\")\n",
    "    image = ImageOps.invert(image)\n",
    "    image = image.filter(ImageFilter.MedianFilter())\n",
    "    image = ImageOps.autocontrast(image)\n",
    "    # Binarização para reduzir ruído\n",
    "    image = image.point(lambda x: 0 if x < 128 else 255, '1')\n",
    "    return image\n",
    "\n",
    "# --- Lê e descriptografa RG ---\n",
    "encrypted_rg_filename = form_data.get(\"rgImagem_encrypted\")\n",
    "img_documento_completo = None\n",
    "\n",
    "if encrypted_rg_filename:\n",
    "    encrypted_path = os.path.join(DATA_DIR, encrypted_rg_filename)\n",
    "    try:\n",
    "        with open(encrypted_path, \"rb\") as f:\n",
    "            encrypted_data = f.read()\n",
    "        decrypted_data = fernet.decrypt(encrypted_data)\n",
    "        img_documento_completo = Image.open(io.BytesIO(decrypted_data))\n",
    "        print(\"[✔] RG descriptografado e carregado.\")\n",
    "        img_documento_completo = preprocess_image(img_documento_completo)\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] Erro ao descriptografar RG: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'rgImagem_encrypted' ausente no JSON.\")\n",
    "\n",
    "# --- Lê a selfie ---\n",
    "selfie_filename = form_data.get(\"selfieImagem_file\")\n",
    "img_selfie = None\n",
    "\n",
    "if selfie_filename:\n",
    "    selfie_path = os.path.join(DATA_DIR, selfie_filename)\n",
    "    try:\n",
    "        img_selfie = Image.open(selfie_path)\n",
    "        print(\"[✔] Selfie carregada.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] Erro ao carregar selfie: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'selfieImagem_file' ausente no JSON.\")\n",
    "\n",
    "# --- Limpeza de CPF ---\n",
    "def clean_cpf(cpf_str):\n",
    "    return re.sub(r\"\\D\", \"\", cpf_str) if isinstance(cpf_str, str) else \"\"\n",
    "\n",
    "# --- OCR e extração ---\n",
    "def perform_ocr_and_extract_data(pil_image, provided_user_data):\n",
    "    results = {\n",
    "        'extracted_text': None,\n",
    "        'extracted_cpf': None,\n",
    "        'cpf_match': False,\n",
    "        'extracted_name': None,\n",
    "        'name_match': False,\n",
    "        'success': False,\n",
    "        'message': ''\n",
    "    }\n",
    "    if pil_image is None:\n",
    "        results['message'] = 'Imagem do documento não fornecida.'\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image, lang='por')\n",
    "        results['extracted_text'] = text\n",
    "\n",
    "        # Extrai CPF no formato 000.000.000-00\n",
    "        m_cpf = re.search(r\"(\\d{3}\\.\\d{3}\\.\\d{3}-\\d{2})\", text)\n",
    "        if m_cpf:\n",
    "            cpf_str = m_cpf.group(1)\n",
    "            results['extracted_cpf'] = cpf_str\n",
    "            # Converte para hash SHA-256 e compara com o hash armazenado\n",
    "            cleaned = clean_cpf(cpf_str)\n",
    "            sha256 = hashlib.sha256(cleaned.encode('utf-8')).hexdigest()\n",
    "            results['cpf_match'] = (sha256 == provided_user_data['cpf_hash'])\n",
    "\n",
    "        # Regex mais flexível para nome (com acentos e variações)\n",
    "        m_name = re.search(r\"[Nn]ome(?:\\s+Social)?\\s*[:\\/-]?\\s*([A-Za-zÀ-ÿ\\s]+)\", text)\n",
    "        if m_name:\n",
    "            name_extracted = m_name.group(1).strip()\n",
    "            results['extracted_name'] = name_extracted\n",
    "            if name_extracted.lower() == provided_user_data['nome'].lower():\n",
    "                results['name_match'] = True\n",
    "\n",
    "        results['success'] = True\n",
    "        results['message'] = 'OCR e comparação concluídos.'\n",
    "    except Exception as e:\n",
    "        results['message'] = f'Erro no OCR: {e}'\n",
    "    return results\n",
    "\n",
    "# --- Executa OCR ---\n",
    "ocr_data = perform_ocr_and_extract_data(img_documento_completo, provided_data)\n",
    "print(\"\\nResultado OCR:\")\n",
    "print(json.dumps(ocr_data, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e7668",
   "metadata": {},
   "source": [
    "Sem criptografia do RG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841cb67ef57bd894",
   "metadata": {},
   "source": [
    "Reconhecimento e Comparação Facial\n",
    "\n",
    "Agora, definimos uma função para lidar com a comparação facial entre a foto do documento e a selfie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351981ce",
   "metadata": {},
   "source": [
    "Ao baixar o tesseract, lembrar de baixar a lingua portuguesa e adicionar na pasta -> C:\\Program Files\\Tesseract-OCR\\tessdata\n",
    "\n",
    "\"por.traineddata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = Path(\"form_data\")\n",
    "KEY_FILE = Path(\"rg_encryption.key\")\n",
    "CASCADE_PATH = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "FACE_SIZE = (150, 150)\n",
    "DISTANCE_THRESHOLD = 60.0  # adjustable threshold for face match\n",
    "\n",
    "\n",
    "def load_fernet_key(key_path: Path) -> Fernet:\n",
    "    \"\"\"\n",
    "    Load Fernet encryption key from file.\n",
    "    \"\"\"\n",
    "    with key_path.open(\"rb\") as f:\n",
    "        key = f.read()\n",
    "    return Fernet(key)\n",
    "\n",
    "\n",
    "def load_latest_form(data_dir: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the most recent JSON form from data_dir.\n",
    "    \"\"\"\n",
    "    json_files = sorted(data_dir.glob(\"*.json\"), key=lambda f: f.stat().st_mtime, reverse=True)\n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No JSON files found in {data_dir}\")\n",
    "    with json_files[0].open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def decrypt_image(encrypted_filename: str, fernet: Fernet, data_dir: Path) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Decrypt an image file and return a PIL Image.\n",
    "    \"\"\"\n",
    "    encrypted_path = data_dir / encrypted_filename\n",
    "    if not encrypted_path or not encrypted_path.exists():\n",
    "        raise FileNotFoundError(f\"Encrypted file not found: {encrypted_path}\")\n",
    "    data = fernet.decrypt(encrypted_path.read_bytes())\n",
    "    return Image.open(io.BytesIO(data))\n",
    "\n",
    "\n",
    "def load_plain_image(filename: str, data_dir: Path) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Load a non-encrypted image from disk as PIL Image.\n",
    "    \"\"\"\n",
    "    img_path = data_dir / filename\n",
    "    if not img_path.exists():\n",
    "        raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
    "    return Image.open(img_path)\n",
    "\n",
    "\n",
    "def pil_to_bgr(img: Image.Image) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert PIL Image to OpenCV BGR numpy array.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(np.array(img.convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "def detect_face(image_bgr: np.ndarray, cascade: cv2.CascadeClassifier) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Detect the first face in a BGR image, crop and resize it.\n",
    "    Returns the grayscale face ROI or None.\n",
    "    \"\"\"\n",
    "    faces = cascade.detectMultiScale(image_bgr, scaleFactor=1.1, minNeighbors=5)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x, y, w, h = faces[0]\n",
    "    face = image_bgr[y:y+h, x:x+w]\n",
    "    face_resized = cv2.resize(face, FACE_SIZE)\n",
    "    return cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def compare_faces(gray1: np.ndarray, gray2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute mean absolute difference between two grayscale face images.\n",
    "    \"\"\"\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    return float(np.mean(diff))\n",
    "\n",
    "\n",
    "def perform_face_comparison_opencv(\n",
    "    img1_pil: Image.Image, img2_pil: Image.Image, threshold: float = DISTANCE_THRESHOLD\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compare two PIL images containing faces using OpenCV Haar cascades.\n",
    "    Returns a dict with match result, distance, and status.\n",
    "    \"\"\"\n",
    "    results: Dict[str, Any] = {\n",
    "        'face_match': False,\n",
    "        'distance': None,\n",
    "        'success': False,\n",
    "        'message': ''\n",
    "    }\n",
    "    try:\n",
    "        img1_bgr = pil_to_bgr(img1_pil)\n",
    "        img2_bgr = pil_to_bgr(img2_pil)\n",
    "\n",
    "        cascade = cv2.CascadeClassifier(CASCADE_PATH)\n",
    "        if cascade.empty():\n",
    "            raise RuntimeError(f\"Failed to load cascade classifier at {CASCADE_PATH}\")\n",
    "\n",
    "        face1 = detect_face(img1_bgr, cascade)\n",
    "        face2 = detect_face(img2_bgr, cascade)\n",
    "\n",
    "        if face1 is None or face2 is None:\n",
    "            results['message'] = \"No face detected in one or both images.\"\n",
    "            return results\n",
    "\n",
    "        distance = compare_faces(face1, face2)\n",
    "        results['distance'] = float(distance)\n",
    "        results['face_match'] = bool(distance < threshold)\n",
    "        results['success'] = True\n",
    "        results['message'] = \"Comparison successful with OpenCV.\"\n",
    "    except Exception as e:\n",
    "        results['message'] = f\"Error during face comparison: {e}\"\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    fernet = load_fernet_key(KEY_FILE)\n",
    "    form_data = load_latest_form(DATA_DIR)\n",
    "\n",
    "    # Decrypt RG image\n",
    "    encrypted_rg = form_data.get(\"rgImagem_encrypted\")\n",
    "    img_doc = decrypt_image(encrypted_rg, fernet, DATA_DIR)\n",
    "\n",
    "    # Load selfie (not encrypted)\n",
    "    selfie_filename = form_data.get(\"selfieImagem_file\")\n",
    "    img_selfie = load_plain_image(selfie_filename, DATA_DIR)\n",
    "\n",
    "    # Run comparison\n",
    "    result = perform_face_comparison_opencv(img_doc, img_selfie)\n",
    "\n",
    "    # Print JSON-safe result\n",
    "    print(json.dumps(result, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f93b55c4ba59c",
   "metadata": {},
   "source": [
    "### 5. Feedback de Validação Final Combinado\n",
    "\n",
    "Esta função recebe os resultados das etapas anteriores e fornece um veredito final e feedback detalhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57438407d029bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def provide_final_validation_feedback(ocr_results, face_results):\n",
    "    \"\"\"\n",
    "    Combina os resultados do OCR/Dados e Reconhecimento Facial para dar o feedback final.\n",
    "\n",
    "    Args:\n",
    "        ocr_results (dict): Dicionário com resultados do OCR e comparação de dados.\n",
    "        face_results (dict): Dicionário com resultados da comparação facial.\n",
    "    \"\"\"\n",
    "    print(\"--- Resultado da Validação de Identidade ---\")\n",
    "\n",
    "    validation_status = \"Inválido\"\n",
    "    messages = []\n",
    "\n",
    "    # Avaliar resultados do OCR e Dados\n",
    "    if not ocr_results['success']:\n",
    "        messages.append(f\"Falha no processamento de dados do documento: {ocr_results['message']}\")\n",
    "    else:\n",
    "        if not ocr_results['name_match']:\n",
    "            messages.append(\"O nome extraído do documento NÃO confere com o nome fornecido.\")\n",
    "        if not ocr_results['cpf_match']:\n",
    "             messages.append(\"O CPF extraído do documento NÃO confere com o CPF fornecido.\")\n",
    "        if ocr_results['name_match'] and ocr_results['cpf_match']:\n",
    "             messages.append(\"Dados de Nome e CPF do documento conferem com os dados fornecidos.\")\n",
    "        elif ocr_results['success'] and not (ocr_results['name_match'] or ocr_results['cpf_match']):\n",
    "             messages.append(\"Nenhum dado chave (Nome, CPF) pôde ser confirmado a partir do documento ou não confere com os dados fornecidos.\")\n",
    "\n",
    "\n",
    "    # Avaliar resultados da Comparação Facial\n",
    "    if not face_results['success']:\n",
    "        messages.append(f\"Falha no processamento facial: {face_results['message']}\")\n",
    "    else:\n",
    "        if face_results['face_match']:\n",
    "            messages.append(f\"A face na selfie corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "        else:\n",
    "            messages.append(f\"A face na selfie NÃO corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "\n",
    "\n",
    "    # Determinar status final\n",
    "    # Condição para Válido: OCR processado com sucesso + Dados de Nome E CPF conferem + Comparação facial deu match\n",
    "    # Note: A lógica de validação pode ser ajustada conforme a regra de negócio.\n",
    "    # Aqui, exigimos match nos dados essenciais E match facial.\n",
    "    if ocr_results['success'] and ocr_results['name_match'] and ocr_results['cpf_match'] and face_results['success'] and face_results['face_match']:\n",
    "         validation_status = \"Válido\"\n",
    "         messages.append(\"Todas as verificações de identidade foram bem-sucedidas.\")\n",
    "    else:\n",
    "         validation_status = \"Inválido\"\n",
    "         messages.append(\"A validação de identidade falhou devido às inconsistências ou erros acima.\")\n",
    "\n",
    "\n",
    "    # --- Exibir o Feedback ---\n",
    "    print(f\"\\nSTATUS FINAL: {validation_status}\")\n",
    "    print(\"\\nDetalhes:\")\n",
    "    for msg in messages:\n",
    "        print(f\"- {msg}\")\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Executar a etapa de Feedback Final ---\n",
    "# Certifique-se de que ocr_data_results e face_comparison_results estão definidos\n",
    "if 'ocr_data_results' in locals() and 'face_comparison_results' in locals():\n",
    "     provide_final_validation_feedback(ocr_data_results, face_comparison_results)\n",
    "else:\n",
    "     print(\"Resultados das etapas anteriores (OCR e Reconhecimento Facial) não disponíveis.\")\n",
    "     print(\"Por favor, execute todas as células em ordem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e96c7714096a8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Integração com Redes Sociais (Simulada)</h3> </div>\n",
    "\n",
    "- **Linkagem de Contas:** Na ausência de integrações reais, simular o processo solicitando ao usuário os nomes de usuário ou perfis em redes sociais (Twitter, Facebook, Instagram). Criar células de código comentadas que demonstram como usar APIs (ex: `tweepy` para Twitter, `facebook-sdk` para Facebook) para conectar as contas.  \n",
    "- **Extração de Atividades Relacionadas a e-sports:** Para cada rede social simulada, mostrar como coletar dados relevantes: por exemplo, obter os últimos *tweets* do usuário e filtrar menções a e-sports ou FURIA; listar as páginas seguidas no Facebook com temas de gaming; ou verificar hashtags usadas em posts do Instagram. Usar `requests` e `BeautifulSoup` ou clientes de API para simulação. Armazenar essas informações em DataFrames para análise.  \n",
    "- **Monitoramento de Interações:** Demonstrar código que analisa curtidas, comentários ou retweets em publicações de e-sports (fingindo as permissões de API). Por exemplo, usar `tweepy` para buscar tweets que mencionem FURIA ou eventos de e-sports que o usuário retuitou ou comentou.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc903631095407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5023f63bcefe89",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Enriquecimento de Perfil com Dados Sociais e Multimídia</h3> </div>\n",
    "\n",
    "- **Análise de Comentários:** Para integrar comentários prévios do usuário no YouTube, Reddit e Twitter, incluir blocos que consumam APIs ou dados locais de análise anterior (supondo que existam). Usar `google-api-python-client` para extrair comentários de vídeos de e-sports do YouTube, `PRAW` para posts/comentários no Reddit, e `tweepy` ou dados simulados para tweets.  \n",
    "- **Processamento de Linguagem Natural:** Aplicar NLP para entender o perfil do usuário: usar bibliotecas como `transformers` ou `spaCy` para classificar sentimento, identificar tópicos ou palavras-chave frequentes nesses comentários. Por exemplo, gerar um gráfico de palavras-chave mais mencionadas em e-sports, ou uma análise de sentimento geral sobre jogos específicos.  \n",
    "- **Integração de Informações:** Combinar esses insights com os interesses declarados pelo usuário. Exibir visualmente (via `matplotlib` ou `seaborn`) uma nuvem de palavras ou gráfico que mostre as categorias de e-sports mais relevantes para o perfil (baseado em interesses + análise de comentários).  \n",
    "- **Perfis em Sites de e-Sports:** Permitir que o usuário insira links para seus perfis em plataformas de e-sports (como GameBattles, HLTV, Liquipedia). Usar `requests` e `BeautifulSoup` para raspar detalhes do perfil (jogos, histórico de partidas). Em seguida, aplicar um modelo de IA (ex: `transformers` BERT) para classificar se o conteúdo textual do perfil é relevante às preferências do usuário (por exemplo, buscando termos de jogos citados pelo usuário). Mostrar se há “match” entre interesses do usuário e informações do perfil scraped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc151832ad30fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e65090fbbfcb5a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Estruturação do Notebook</h3> </div>\n",
    "\n",
    "- Organizar o notebook em seções claras conforme as etapas acima: **Coleta de Dados**, **Validação de Identidade**, **Integração de Redes Sociais**, **Enriquecimento com Dados Sociais**, **Conclusão**.  \n",
    "- Incluir explicações breves em cada seção usando células Markdown, resumindo o objetivo daquela etapa. Combinar descrições em texto com células de código demonstrativas.  \n",
    "- Sugerir bibliotecas específicas no contexto de cada etapa: por exemplo, mencionar `ipywidgets` ou `streamlit` na coleta de dados, `pytesseract`/`OpenCV` na validação de documentos, `tweepy`/`PRAW`/`BeautifulSoup` na integração social, e `transformers`/`spaCy` na análise de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255b8c4d4857ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfadd7aa567531f2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Dicas de Apresentação do Protótipo</h3> </div>\n",
    "\n",
    "- **Formatação Atraente:** Usar cabeçalhos (`#`, `##`), listas e imagens (logotipos de e-sports, ícones de redes sociais) para tornar o notebook visualmente agradável. Células Markdown bem elaboradas ajudam na legibilidade.  \n",
    "- **Interatividade:** Incluir elementos interativos (sliders, botões de upload, caixas de seleção) via `ipywidgets` para simular um fluxo real de uso. Isso torna a demonstração dinâmica mesmo no ambiente de notebook.  \n",
    "- **Visualização de Dados:** Aproveitar gráficos (matplotlib, seaborn ou plotly) para mostrar perfis de interesse ou resultados das análises de comentários. Um gráfico de barras ou nuvem de palavras torna o conteúdo mais didático.  \n",
    "- **Narração do Código:** Inserir comentários explicativos e outputs de exemplo que guiem o avaliador pelo processo passo a passo. Ao final, apresentar um breve resumo dos resultados obtidos para evidenciar que todos os requisitos foram atendidos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37fafd0bfde477",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Conclusão</h3> </div>\n",
    "\n",
    "Este plano garante uma implementação completa dos requisitos do desafio, integrando coleta de informações pessoais e de interesse em e-sports, validação de identidade baseada em IA, simulação de integração social e enriquecimento de perfil com dados externos. A organização em seções claras, o uso de bibliotecas especializadas (ex: **Streamlit/ipywidgets** para interfaces, **OpenCV/face_recognition** para validação, **transformers/spaCy** para IA, **pandas** para dados) e as sugestões de apresentação asseguram uma entrega alinhada e de fácil acompanhamento, mesmo no formato de notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cbc009a6d1ea09",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h1> FURIA Know Your Fan </h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80bf6c08fb5459",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3> Todos os pip, ferramentas e bibliotecas utilizadas </h3> </div>\n",
    "\n",
    "- pip install python-dotenv ipywidgets cryptography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ac0276a6352a1",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3> Chave API Oculta (Arquivo .env) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba830f86466a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar variáveis do .env\n",
    "load_dotenv()\n",
    "\n",
    "chave_api = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aac8180eeb5b5c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Coleta de Dados Básicos e Interesses Relacionados à FURIA</h3> </div>\n",
    "  \n",
    "- **Formulário Inicial:** Criar um formulário em Jupyter Notebook (usando `ipywidgets` ou `Streamlit`) para capturar dados pessoais fundamentais: nome, CPF, endereço, data de nascimento, email etc. Validar formato de CPF (biblioteca `python-bcpf` ou validação via regex) e outros campos para evitar erros de digitação.  \n",
    "\n",
    "- **Interesses e Atividades em e-sports:** Incluir no notebook seções ou perguntas interativas sobre interesses em e-sports, times preferidos (FURIA), jogos mais acompanhados, frequência de eventos assistidos, ingressos ou periféricos adquiridos no último ano. Utilizar `pandas` para estruturar as respostas em um DataFrame. Poder-se-á simular coleta de dados de APIs públicas de eventos (por exemplo, dados de torneios CS:GO) ou pedir ao usuário que importe seu histórico (como um CSV de compras) para preencher esse perfil de maneira realista.  \n",
    "\n",
    "- **Compras Relacionadas:** Se for aplicável, permitir o upload de extratos simplificados ou listas de compras (como merch de teams e-sports). Usar `pandas` ou `openpyxl` para ler esses arquivos e filtrar itens de interesse (palavras-chave relacionadas a jogos, marcas de e-sports, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dca973f7b28f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servidor rodando em http://localhost:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Apr/2025 17:27:33] \"GET /form.html HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dados processados (CPF com hash) salvos em: form_data\\8cf071a1-0212-475e-8e87-45d0959b3fb1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Apr/2025 17:27:43] \"POST /submit HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "                                    # Rodando no Navegador\n",
    "\n",
    "import http.server\n",
    "import socketserver\n",
    "import webbrowser\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "import hashlib \n",
    "\n",
    "PORT = 8080\n",
    "DATA_DIR = \"form_data\"\n",
    "\n",
    "class MyHandler(http.server.SimpleHTTPRequestHandler):\n",
    "    def do_POST(self):\n",
    "        if self.path == '/submit':\n",
    "            content_length = int(self.headers['Content-Length'])\n",
    "            post_data_bytes = self.rfile.read(content_length)\n",
    "\n",
    "            # Decodificar os dados recebidos para string\n",
    "            post_data_str = post_data_bytes.decode('utf-8')\n",
    "\n",
    "            try:\n",
    "                # Tentar carregar os dados como JSON\n",
    "                dados_recebidos = json.loads(post_data_str)\n",
    "\n",
    "                # Verificar se a chave 'cpf' existe\n",
    "                if 'cpf' in dados_recebidos:\n",
    "                    cpf_original = dados_recebidos['cpf']\n",
    "                \n",
    "                    cpf_hashed = hashlib.sha256(cpf_original.encode('utf-8')).hexdigest()\n",
    "                    # Substituir o CPF original pelo hash\n",
    "                    dados_recebidos['cpf'] = cpf_hashed\n",
    "                else:\n",
    "                     print(\"Aviso: Chave 'cpf' não encontrada nos dados recebidos.\")\n",
    "\n",
    "                # Gerar ID único\n",
    "                user_id = str(uuid.uuid4())\n",
    "\n",
    "                # Criar o diretório se não existir\n",
    "                if not os.path.exists(DATA_DIR):\n",
    "                    os.makedirs(DATA_DIR)\n",
    "\n",
    "                # Caminho do arquivo para salvar\n",
    "                file_path = os.path.join(DATA_DIR, f\"{user_id}.json\")\n",
    "\n",
    "                # Salvar os dados modificados (com CPF hasheado) em JSON\n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    # Salvar o dicionário Python diretamente como JSON\n",
    "                    json.dump(dados_recebidos, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "                print(f\"\\n✅ Dados processados (CPF com hash) salvos em: {file_path}\")\n",
    "\n",
    "                # Enviar resposta de sucesso\n",
    "                self.send_response(200)\n",
    "                self.send_header('Content-type', 'application/json')\n",
    "                self.end_headers()\n",
    "                self.wfile.write(json.dumps({'status': 'success', 'message': 'Dados recebidos e salvos com sucesso!'}).encode('utf-8'))\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"\\n❌ Erro: Não foi possível decodificar os dados JSON recebidos.\")\n",
    "                self.send_error(400, \"Bad Request: Invalid JSON data\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\n❌ Erro ao processar a requisição: {e}\")\n",
    "                self.send_error(500, \"Internal Server Error\")\n",
    "\n",
    "        else:\n",
    "            super().do_GET()\n",
    "\n",
    "def run_server():\n",
    "    with socketserver.TCPServer((\"\", PORT), MyHandler) as httpd:\n",
    "        print(f\"Servidor rodando em http://localhost:{PORT}\")\n",
    "        webbrowser.open(f\"http://localhost:{PORT}/form.html\")\n",
    "        httpd.serve_forever()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6996e942e24f04",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Validação de Identidade com Abordagem de IA</h3> </div>\n",
    "\n",
    "- **Upload de Documentos:** Incluir um widget de upload de arquivos de imagem (RG, CNH ou passaporte) e, opcionalmente, uma selfie do usuário.  \n",
    "- **OCR e Extração de Dados:** Utilizar uma biblioteca de OCR como `pytesseract` ou `easyocr` para extrair texto do documento. Comparar nome e CPF extraídos com os dados básicos fornecidos para consistência.  \n",
    "- **Reconhecimento Facial:** Para fortalecer a validação, aplicar uma técnica de reconhecimento facial simples. Usar bibliotecas como `face_recognition` ou `OpenCV` com modelos pré-treinados para detectar rostos na selfie e na foto do documento, e então verificar se pertencem à mesma pessoa (por exemplo, comparando descritores faciais).  \n",
    "- **Feedback de Validação:** Exibir no notebook resultados da validação (válido/inválido) com base na correspondência de texto e face. Fornecer mensagens orientativas caso haja inconsistências (ex: “CPF não confere com o documento enviado”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed12b2bdcdbcf6",
   "metadata": {},
   "source": [
    "### Instale as bibliotecas necessárias\n",
    "\n",
    "- pytesseract (requer Tesseract OCR engine instalado separadamente)\n",
    " \n",
    "- Pillow (dependência do pytesseract)\n",
    " \n",
    "- face_recognition (requer dlib, pode ser complexo instalar em alguns sistemas)\n",
    "\n",
    "- ipywidgets (para o widget de upload)\n",
    "\n",
    "<br>\n",
    "\n",
    "```pip install pytesseract Pillow face_recognition ipywidgets ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3f778faa45d99",
   "metadata": {},
   "source": [
    "### 1. Preparação e Upload de Documentos\n",
    "\n",
    "Começamos pedindo ao usuário para carregar os arquivos necessários via widget. Precisaremos da imagem do documento completo para OCR e extração de dados, e possivelmente uma imagem separada da foto do documento e uma selfie para reconhecimento facial. Vamos criar widgets separados para clareza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27da3aaf349460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Widgets de Upload\n",
    "print(\"--- Upload de Documentos ---\")\n",
    "\n",
    "print(\"\\nPor favor, carregue a IMAGEM COMPLETA do documento (RG, CNH, Passaporte):\")\n",
    "uploader_documento_completo = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False\n",
    ")\n",
    "display(uploader_documento_completo)\n",
    "\n",
    "print(\"\\nPor favor, carregue a IMAGEM SOMENTE da FOTO presente no documento:\")\n",
    "uploader_foto_documento = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False\n",
    ")\n",
    "display(uploader_foto_documento)\n",
    "\n",
    "print(\"\\nPor favor, carregue sua SELFIE:\")\n",
    "uploader_selfie = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False\n",
    ")\n",
    "display(uploader_selfie)\n",
    "\n",
    "print(\"\\nCarregue os arquivos usando os botões acima. As próximas etapas processarão os arquivos carregados.\")\n",
    "\n",
    "# Variáveis para armazenar as imagens PIL carregadas\n",
    "img_documento_completo = None\n",
    "img_foto_documento = None\n",
    "img_selfie = None\n",
    "\n",
    "# Função para carregar uma imagem de um widget de upload\n",
    "def load_image_from_widget(uploader_widget):\n",
    "    if uploader_widget.value:\n",
    "        # Pega o primeiro arquivo (multiple=False)\n",
    "        uploaded_file_info = uploader_widget.value[next(iter(uploader_widget.value))]\n",
    "        file_content = uploaded_file_info['content']\n",
    "        try:\n",
    "            img = Image.open(io.BytesIO(file_content))\n",
    "            print(f\"'{uploaded_file_info['metadata']['name']}' carregado com sucesso.\")\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao abrir a imagem '{uploaded_file_info['metadata']['name']}': {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Nenhum arquivo carregado no widget.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e444dee6b1a2ab62",
   "metadata": {},
   "source": [
    "### 2. Processar Uploads e Preparar Imagens\n",
    "\n",
    "Execute esta célula depois que todos os arquivos foram carregados nos widgets acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22357c1098780d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Processando Imagens Carregadas ---\")\n",
    "clear_output(wait=True) # Limpa a saída anterior dos widgets para organização\n",
    "\n",
    "# Carregar as imagens usando a função auxiliar\n",
    "img_documento_completo = load_image_from_widget(uploader_documento_completo)\n",
    "img_foto_documento = load_image_from_widget(uploader_foto_documento)\n",
    "img_selfie = load_image_from_widget(uploader_selfie)\n",
    "\n",
    "# Verificar se as imagens essenciais foram carregadas\n",
    "if img_documento_completo and img_foto_documento and img_selfie:\n",
    "    print(\"\\nTodas as imagens essenciais foram carregadas. Próximas etapas: OCR e Reconhecimento Facial.\")\n",
    "    # Opcional: Exibir miniaturas das imagens carregadas para confirmação\n",
    "    # from IPython.display import display as display_image\n",
    "    # print(\"\\nVisualização rápida:\")\n",
    "    # display_image(img_documento_completo.resize((100, int(100 * img_documento_completo.size[1] / img_documento_completo.size[0]))))\n",
    "    # display_image(img_foto_documento.resize((100, int(100 * img_foto_documento.size[1] / img_foto_documento.size[0]))))\n",
    "    # display_image(img_selfie.resize((100, int(100 * img_selfie.size[1] / img_selfie.size[0]))))\n",
    "\n",
    "else:\n",
    "    print(\"\\nErro: Nem todas as imagens necessárias foram carregadas. Por favor, carregue todos os arquivos usando os widgets na célula anterior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e06c15ea2efa4",
   "metadata": {},
   "source": [
    "### 3. OCR, Extração e Comparação de Dados Textuais\n",
    "\n",
    "Definimos uma função para realizar o OCR na imagem do documento completo, extrair o texto, tentar encontrar Nome e CPF e compará-los com dados fornecidos (vamos simular esses dados fornecidos para o exemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82efa4ee6dc53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# --- Carregar dados do JSON gerado pelo formulário ---\n",
    "json_file = 'form_data/<user_id>.json'  # Atualize para o nome do arquivo salvo pelo servidor\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    form_data = json.load(f)\n",
    "\n",
    "# Extrair dados fornecidos\n",
    "provided_data = {\n",
    "    'nome': form_data.get('nome', ''),\n",
    "    'cpf': form_data.get('cpf', '')\n",
    "}\n",
    "\n",
    "# Decodificar imagem do documento (base64) para PIL Image\n",
    "foto_doc_b64 = form_data.get('foto_documento', '')\n",
    "img_documento_completo = None\n",
    "if foto_doc_b64:\n",
    "    try:\n",
    "        raw_bytes = base64.b64decode(foto_doc_b64)\n",
    "        img_documento_completo = Image.open(io.BytesIO(raw_bytes))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao decodificar documento: {e}\")\n",
    "else:\n",
    "    print(\"Campo 'foto_documento' ausente no JSON.\")\n",
    "\n",
    "# Função para limpar CPF\n",
    "\n",
    "def clean_cpf(cpf_str):\n",
    "    if isinstance(cpf_str, str):\n",
    "        return cpf_str.replace('.', '').replace('-', '').strip()\n",
    "    return ''\n",
    "\n",
    "# Função de OCR e extração\n",
    "\n",
    "def perform_ocr_and_extract_data(pil_image, provided_user_data):\n",
    "    results = {\n",
    "        'extracted_text': None,\n",
    "        'extracted_cpf': None,\n",
    "        'name_match': False,\n",
    "        'cpf_match': False,\n",
    "        'success': False,\n",
    "        'message': ''\n",
    "    }\n",
    "    if pil_image is None:\n",
    "        results['message'] = 'Imagem do documento não fornecida.'\n",
    "        return results\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(pil_image, lang='por')\n",
    "        results['extracted_text'] = text\n",
    "\n",
    "        # Extrair CPF\n",
    "        m = re.search(r\"\\d{2,3}\\.\\d{3}\\.\\d{3}-?\\d{2}\", text)\n",
    "        if m:\n",
    "            results['extracted_cpf'] = m.group(0)\n",
    "\n",
    "        # Comparar CPF\n",
    "        if results['extracted_cpf'] and provided_user_data['cpf']:\n",
    "            results['cpf_match'] = (clean_cpf(results['extracted_cpf']) == clean_cpf(provided_user_data['cpf']))\n",
    "\n",
    "        # Comparar Nome (simplificado)\n",
    "        name_parts = provided_user_data['nome'].lower().split()\n",
    "        if len(name_parts) >= 2 and name_parts[0] in text.lower() and name_parts[-1] in text.lower():\n",
    "            results['name_match'] = True\n",
    "\n",
    "        results['success'] = True\n",
    "        results['message'] = 'OCR e comparação concluídos.'\n",
    "    except Exception as e:\n",
    "        results['message'] = f'Erro no OCR: {e}'\n",
    "    return results\n",
    "\n",
    "# Executar OCR e exibir resultados\n",
    "ocr_data = perform_ocr_and_extract_data(img_documento_completo, provided_data)\n",
    "print(\"Resultado OCR:\", ocr_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841cb67ef57bd894",
   "metadata": {},
   "source": [
    "### 4. Reconhecimento e Comparação Facial\n",
    "\n",
    "Agora, definimos uma função para lidar com a comparação facial entre a foto do documento e a selfie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28720deba99a0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "def perform_face_comparison(img_documento_foto, img_selfie_foto):\n",
    "    \"\"\"\n",
    "    Compara a face na foto do documento com a face na selfie.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Resultados da comparação facial ({'face_match', 'distance', 'success', 'message'})\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'face_match': False,\n",
    "        'distance': None,\n",
    "        'success': False, # Indica se o processo de comparação ocorreu sem erros graves\n",
    "        'message': 'Comparação facial pendente.'\n",
    "    }\n",
    "\n",
    "    if img_documento_foto is None or img_selfie_foto is None:\n",
    "        results['message'] = 'Erro: Imagens da foto do documento e/ou selfie não fornecidas para comparação facial.'\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        print(\"Iniciando comparação facial...\")\n",
    "\n",
    "        # Converter imagens PIL para array numpy (face_recognition trabalha com numpy)\n",
    "        img_doc_np = np.array(img_documento_foto.convert('RGB'))\n",
    "        img_selfie_np = np.array(img_selfie_foto.convert('RGB'))\n",
    "\n",
    "\n",
    "        # Encontrar os 'encodings' (características únicas) das faces\n",
    "        print(\"Extraindo encodings da foto do documento...\")\n",
    "        document_face_encodings = face_recognition.face_encodings(img_doc_np)\n",
    "\n",
    "        print(\"Extraindo encodings da selfie...\")\n",
    "        selfie_face_encodings = face_recognition.face_encodings(img_selfie_np)\n",
    "\n",
    "        if not document_face_encodings:\n",
    "            results['message'] = \"Erro: Não foi possível detectar um rosto na foto do documento.\"\n",
    "            print(results['message'])\n",
    "            return results\n",
    "        if not selfie_face_encodings:\n",
    "            results['message'] = \"Erro: Não foi possível detectar um rosto na selfie.\"\n",
    "            print(results['message'])\n",
    "            return results\n",
    "\n",
    "        # Comparar o primeiro rosto encontrado em cada imagem\n",
    "        known_face_encoding = document_face_encodings[0]\n",
    "        unknown_face_encoding = selfie_face_encodings[0]\n",
    "\n",
    "        # Comparar faces. Retorna True se for um match (abaixo de um limiar interno, padrão 0.6)\n",
    "        results['face_match'] = face_recognition.compare_faces([known_face_encoding], unknown_face_encoding)[0]\n",
    "\n",
    "        # Calcular a distância facial. Menor distância = maior similaridade.\n",
    "        # O limiar de 0.6 mencionado antes é a distância padrão para `compare_faces`.\n",
    "        results['distance'] = face_recognition.face_distance([known_face_encoding], unknown_face_encoding)[0]\n",
    "\n",
    "        results['success'] = True\n",
    "        results['message'] = 'Comparação facial concluída.'\n",
    "        print(results['message'])\n",
    "\n",
    "    except Exception as e:\n",
    "        results['message'] = f\"Erro durante o reconhecimento facial: {e}\"\n",
    "        results['success'] = False\n",
    "        print(results['message'])\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Executar a etapa de Comparação Facial ---\n",
    "# Certifique-se de que img_foto_documento e img_selfie estão definidos antes de executar\n",
    "if 'img_foto_documento' in locals() and 'img_selfie' in locals() and img_foto_documento is not None and img_selfie is not None:\n",
    "     face_comparison_results = perform_face_comparison(img_foto_documento, img_selfie)\n",
    "     print(\"\\n--- Resultados da Etapa de Reconhecimento Facial ---\")\n",
    "     print(f\"Status: {'Sucesso' if face_comparison_results['success'] else 'Falha no Processo'}\")\n",
    "     print(f\"Mensagem do Processo: {face_comparison_results['message']}\")\n",
    "     if face_comparison_results['success']:\n",
    "        print(f\"Resultado da Comparação (Match): {face_comparison_results['face_match']}\")\n",
    "        print(f\"Distância Facial: {face_comparison_results['distance']:.4f} (Menor é mais similar. Limiar padrão ~0.6)\")\n",
    "     print(\"-------------------------------------------------\")\n",
    "\n",
    "elif 'img_foto_documento' not in locals() or img_foto_documento is None:\n",
    "    print(\"A imagem da foto do documento não foi carregada. Execute a(s) célula(s) de upload primeiro.\")\n",
    "    face_comparison_results = {'success': False, 'message': 'Imagem da foto do documento não carregada.'}\n",
    "elif 'img_selfie' not in locals() or img_selfie is None:\n",
    "     print(\"A imagem da selfie não foi carregada. Execute a(s) célula(s) de upload primeiro.\")\n",
    "     face_comparison_results = {'success': False, 'message': 'Imagem da selfie não carregada.'}\n",
    "else:\n",
    "     print(\"Imagens necessárias para reconhecimento facial não foram carregadas. Execute a(s) célula(s) de upload primeiro.\")\n",
    "     face_comparison_results = {'success': False, 'message': 'Imagens essenciais não carregadas.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f93b55c4ba59c",
   "metadata": {},
   "source": [
    "### 5. Feedback de Validação Final Combinado\n",
    "\n",
    "Esta função recebe os resultados das etapas anteriores e fornece um veredito final e feedback detalhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57438407d029bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def provide_final_validation_feedback(ocr_results, face_results):\n",
    "    \"\"\"\n",
    "    Combina os resultados do OCR/Dados e Reconhecimento Facial para dar o feedback final.\n",
    "\n",
    "    Args:\n",
    "        ocr_results (dict): Dicionário com resultados do OCR e comparação de dados.\n",
    "        face_results (dict): Dicionário com resultados da comparação facial.\n",
    "    \"\"\"\n",
    "    print(\"--- Resultado da Validação de Identidade ---\")\n",
    "\n",
    "    validation_status = \"Inválido\"\n",
    "    messages = []\n",
    "\n",
    "    # Avaliar resultados do OCR e Dados\n",
    "    if not ocr_results['success']:\n",
    "        messages.append(f\"Falha no processamento de dados do documento: {ocr_results['message']}\")\n",
    "    else:\n",
    "        if not ocr_results['name_match']:\n",
    "            messages.append(\"O nome extraído do documento NÃO confere com o nome fornecido.\")\n",
    "        if not ocr_results['cpf_match']:\n",
    "             messages.append(\"O CPF extraído do documento NÃO confere com o CPF fornecido.\")\n",
    "        if ocr_results['name_match'] and ocr_results['cpf_match']:\n",
    "             messages.append(\"Dados de Nome e CPF do documento conferem com os dados fornecidos.\")\n",
    "        elif ocr_results['success'] and not (ocr_results['name_match'] or ocr_results['cpf_match']):\n",
    "             messages.append(\"Nenhum dado chave (Nome, CPF) pôde ser confirmado a partir do documento ou não confere com os dados fornecidos.\")\n",
    "\n",
    "\n",
    "    # Avaliar resultados da Comparação Facial\n",
    "    if not face_results['success']:\n",
    "        messages.append(f\"Falha no processamento facial: {face_results['message']}\")\n",
    "    else:\n",
    "        if face_results['face_match']:\n",
    "            messages.append(f\"A face na selfie corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "        else:\n",
    "            messages.append(f\"A face na selfie NÃO corresponde à face na foto do documento (Distância: {face_results['distance']:.4f}).\")\n",
    "\n",
    "\n",
    "    # Determinar status final\n",
    "    # Condição para Válido: OCR processado com sucesso + Dados de Nome E CPF conferem + Comparação facial deu match\n",
    "    # Note: A lógica de validação pode ser ajustada conforme a regra de negócio.\n",
    "    # Aqui, exigimos match nos dados essenciais E match facial.\n",
    "    if ocr_results['success'] and ocr_results['name_match'] and ocr_results['cpf_match'] and face_results['success'] and face_results['face_match']:\n",
    "         validation_status = \"Válido\"\n",
    "         messages.append(\"Todas as verificações de identidade foram bem-sucedidas.\")\n",
    "    else:\n",
    "         validation_status = \"Inválido\"\n",
    "         messages.append(\"A validação de identidade falhou devido às inconsistências ou erros acima.\")\n",
    "\n",
    "\n",
    "    # --- Exibir o Feedback ---\n",
    "    print(f\"\\nSTATUS FINAL: {validation_status}\")\n",
    "    print(\"\\nDetalhes:\")\n",
    "    for msg in messages:\n",
    "        print(f\"- {msg}\")\n",
    "\n",
    "    print(\"------------------------------------------\")\n",
    "\n",
    "\n",
    "# --- Executar a etapa de Feedback Final ---\n",
    "# Certifique-se de que ocr_data_results e face_comparison_results estão definidos\n",
    "if 'ocr_data_results' in locals() and 'face_comparison_results' in locals():\n",
    "     provide_final_validation_feedback(ocr_data_results, face_comparison_results)\n",
    "else:\n",
    "     print(\"Resultados das etapas anteriores (OCR e Reconhecimento Facial) não disponíveis.\")\n",
    "     print(\"Por favor, execute todas as células em ordem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e96c7714096a8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Integração com Redes Sociais (Simulada)</h3> </div>\n",
    "\n",
    "- **Linkagem de Contas:** Na ausência de integrações reais, simular o processo solicitando ao usuário os nomes de usuário ou perfis em redes sociais (Twitter, Facebook, Instagram). Criar células de código comentadas que demonstram como usar APIs (ex: `tweepy` para Twitter, `facebook-sdk` para Facebook) para conectar as contas.  \n",
    "- **Extração de Atividades Relacionadas a e-sports:** Para cada rede social simulada, mostrar como coletar dados relevantes: por exemplo, obter os últimos *tweets* do usuário e filtrar menções a e-sports ou FURIA; listar as páginas seguidas no Facebook com temas de gaming; ou verificar hashtags usadas em posts do Instagram. Usar `requests` e `BeautifulSoup` ou clientes de API para simulação. Armazenar essas informações em DataFrames para análise.  \n",
    "- **Monitoramento de Interações:** Demonstrar código que analisa curtidas, comentários ou retweets em publicações de e-sports (fingindo as permissões de API). Por exemplo, usar `tweepy` para buscar tweets que mencionem FURIA ou eventos de e-sports que o usuário retuitou ou comentou.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc903631095407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5023f63bcefe89",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Enriquecimento de Perfil com Dados Sociais e Multimídia</h3> </div>\n",
    "\n",
    "- **Análise de Comentários:** Para integrar comentários prévios do usuário no YouTube, Reddit e Twitter, incluir blocos que consumam APIs ou dados locais de análise anterior (supondo que existam). Usar `google-api-python-client` para extrair comentários de vídeos de e-sports do YouTube, `PRAW` para posts/comentários no Reddit, e `tweepy` ou dados simulados para tweets.  \n",
    "- **Processamento de Linguagem Natural:** Aplicar NLP para entender o perfil do usuário: usar bibliotecas como `transformers` ou `spaCy` para classificar sentimento, identificar tópicos ou palavras-chave frequentes nesses comentários. Por exemplo, gerar um gráfico de palavras-chave mais mencionadas em e-sports, ou uma análise de sentimento geral sobre jogos específicos.  \n",
    "- **Integração de Informações:** Combinar esses insights com os interesses declarados pelo usuário. Exibir visualmente (via `matplotlib` ou `seaborn`) uma nuvem de palavras ou gráfico que mostre as categorias de e-sports mais relevantes para o perfil (baseado em interesses + análise de comentários).  \n",
    "- **Perfis em Sites de e-Sports:** Permitir que o usuário insira links para seus perfis em plataformas de e-sports (como GameBattles, HLTV, Liquipedia). Usar `requests` e `BeautifulSoup` para raspar detalhes do perfil (jogos, histórico de partidas). Em seguida, aplicar um modelo de IA (ex: `transformers` BERT) para classificar se o conteúdo textual do perfil é relevante às preferências do usuário (por exemplo, buscando termos de jogos citados pelo usuário). Mostrar se há “match” entre interesses do usuário e informações do perfil scraped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc151832ad30fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e65090fbbfcb5a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Estruturação do Notebook</h3> </div>\n",
    "\n",
    "- Organizar o notebook em seções claras conforme as etapas acima: **Coleta de Dados**, **Validação de Identidade**, **Integração de Redes Sociais**, **Enriquecimento com Dados Sociais**, **Conclusão**.  \n",
    "- Incluir explicações breves em cada seção usando células Markdown, resumindo o objetivo daquela etapa. Combinar descrições em texto com células de código demonstrativas.  \n",
    "- Sugerir bibliotecas específicas no contexto de cada etapa: por exemplo, mencionar `ipywidgets` ou `streamlit` na coleta de dados, `pytesseract`/`OpenCV` na validação de documentos, `tweepy`/`PRAW`/`BeautifulSoup` na integração social, e `transformers`/`spaCy` na análise de linguagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255b8c4d4857ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfadd7aa567531f2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Dicas de Apresentação do Protótipo</h3> </div>\n",
    "\n",
    "- **Formatação Atraente:** Usar cabeçalhos (`#`, `##`), listas e imagens (logotipos de e-sports, ícones de redes sociais) para tornar o notebook visualmente agradável. Células Markdown bem elaboradas ajudam na legibilidade.  \n",
    "- **Interatividade:** Incluir elementos interativos (sliders, botões de upload, caixas de seleção) via `ipywidgets` para simular um fluxo real de uso. Isso torna a demonstração dinâmica mesmo no ambiente de notebook.  \n",
    "- **Visualização de Dados:** Aproveitar gráficos (matplotlib, seaborn ou plotly) para mostrar perfis de interesse ou resultados das análises de comentários. Um gráfico de barras ou nuvem de palavras torna o conteúdo mais didático.  \n",
    "- **Narração do Código:** Inserir comentários explicativos e outputs de exemplo que guiem o avaliador pelo processo passo a passo. Ao final, apresentar um breve resumo dos resultados obtidos para evidenciar que todos os requisitos foram atendidos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37fafd0bfde477",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <h3>Conclusão</h3> </div>\n",
    "\n",
    "Este plano garante uma implementação completa dos requisitos do desafio, integrando coleta de informações pessoais e de interesse em e-sports, validação de identidade baseada em IA, simulação de integração social e enriquecimento de perfil com dados externos. A organização em seções claras, o uso de bibliotecas especializadas (ex: **Streamlit/ipywidgets** para interfaces, **OpenCV/face_recognition** para validação, **transformers/spaCy** para IA, **pandas** para dados) e as sugestões de apresentação asseguram uma entrega alinhada e de fácil acompanhamento, mesmo no formato de notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
